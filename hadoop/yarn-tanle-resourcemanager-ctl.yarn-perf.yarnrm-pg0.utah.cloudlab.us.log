2016-11-20 02:02:04,567 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   host = ctl.yarn-perf.yarnrm-pg0.utah.cloudlab.us/128.110.153.236
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /users/tanle/hadoop/etc/hadoop:/users/tanle/hadoop/etc/hadoop:/users/tanle/hadoop/etc/hadoop:/users/tanle/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/users/tanle/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/users/tanle/hadoop/share/hadoop/common/lib/asm-3.2.jar:/users/tanle/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/users/tanle/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/users/tanle/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/users/tanle/hadoop/share/hadoop/common/lib/junit-4.11.jar:/users/tanle/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/users/tanle/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/users/tanle/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/users/tanle/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/users/tanle/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/users/tanle/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/users/tanle/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/users/tanle/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/users/tanle/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/users/tanle/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/users/tanle/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/users/tanle/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/users/tanle/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/users/tanle/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/users/tanle/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/users/tanle/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/users/tanle/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/users/tanle/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/users/tanle/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/users/tanle/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/users/tanle/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/users/tanle/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/users/tanle/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/users/tanle/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/users/tanle/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/users/tanle/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/users/tanle/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/users/tanle/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/users/tanle/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/users/tanle/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/users/tanle/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/users/tanle/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/users/tanle/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/users/tanle/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/users/tanle/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/users/tanle/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/users/tanle/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/users/tanle/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/users/tanle/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/users/tanle/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/users/tanle/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/users/tanle/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/users/tanle/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/users/tanle/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/users/tanle/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/users/tanle/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/users/tanle/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/users/tanle/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/users/tanle/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/users/tanle/hadoop/share/hadoop/common/lib/activation-1.1.jar:/users/tanle/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/users/tanle/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/users/tanle/hadoop/share/hadoop/common/lib/xz-1.0.jar:/users/tanle/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/users/tanle/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/users/tanle/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/users/tanle/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/users/tanle/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/users/tanle/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/users/tanle/hadoop/share/hadoop/hdfs:/users/tanle/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/users/tanle/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/users/tanle/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/users/tanle/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/users/tanle/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/users/tanle/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/users/tanle/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/users/tanle/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/users/tanle/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/users/tanle/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/users/tanle/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/users/tanle/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/users/tanle/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/users/tanle/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/users/tanle/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/users/tanle/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/users/tanle/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/users/tanle/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/users/tanle/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/users/tanle/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/users/tanle/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/users/tanle/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/users/tanle/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/users/tanle/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/users/tanle/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/users/tanle/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/users/tanle/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/users/tanle/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/users/tanle/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/users/tanle/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/users/tanle/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/users/tanle/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/users/tanle/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/users/tanle/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/users/tanle/hadoop/share/hadoop/yarn/spark-2.0.2-yarn-shuffle.jar:/users/tanle/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/users/tanle/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/users/tanle/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/users/tanle/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/users/tanle/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/users/tanle/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/users/tanle/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/users/tanle/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/users/tanle/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/users/tanle/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/users/tanle/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/users/tanle/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/users/tanle/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/users/tanle/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/users/tanle/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/users/tanle/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/users/tanle/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/users/tanle/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/users/tanle/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/users/tanle/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/users/tanle/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/users/tanle/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/users/tanle/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/users/tanle/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/users/tanle/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/users/tanle/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/users/tanle/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/users/tanle/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/users/tanle/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/users/tanle/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/users/tanle/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/users/tanle/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/users/tanle/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/users/tanle/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/users/tanle/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/users/tanle/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/users/tanle/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/users/tanle/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/users/tanle/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/users/tanle/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/users/tanle/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/users/tanle/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/users/tanle/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/users/tanle/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/users/tanle/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/users/tanle/hadoop/share/hadoop/yarn/spark-2.0.2-yarn-shuffle.jar:/users/tanle/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/users/tanle/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/users/tanle/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/users/tanle/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/users/tanle/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/users/tanle/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/users/tanle/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/users/tanle/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/users/tanle/hadoop/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = https://github.com/lenhattan86/ccra.git -r 64033350a6f1a1c56316dada1a84175618ad3ea1; compiled by 'tanle' on 2016-11-20T08:34Z
STARTUP_MSG:   java = 1.8.0_111
************************************************************/
2016-11-20 02:02:04,577 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2016-11-20 02:02:04,897 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/users/tanle/hadoop/etc/hadoop/core-site.xml
2016-11-20 02:02:04,946 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-11-20 02:02:04,977 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2016-11-20 02:02:05,036 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/users/tanle/hadoop/etc/hadoop/yarn-site.xml
2016-11-20 02:02:05,192 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2016-11-20 02:02:05,390 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2016-11-20 02:02:05,394 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2016-11-20 02:02:05,401 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2016-11-20 02:02:05,437 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2016-11-20 02:02:05,439 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2016-11-20 02:02:05,439 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler
2016-11-20 02:02:05,470 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2016-11-20 02:02:05,471 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2016-11-20 02:02:05,472 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2016-11-20 02:02:05,473 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2016-11-20 02:02:05,539 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-11-20 02:02:05,605 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-11-20 02:02:05,605 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2016-11-20 02:02:05,620 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2016-11-20 02:02:05,626 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2016-11-20 02:02:05,628 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2016-11-20 02:02:05,630 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2016-11-20 02:02:05,631 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-11-20 02:02:05,664 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AllocationFileLoaderService: Loading allocation file /users/tanle/hadoop/etc/fair-scheduler.xml
2016-11-20 02:02:05,693 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2016-11-20 02:02:05,693 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2016-11-20 02:02:05,707 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2016-11-20 02:02:05,707 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2016-11-20 02:02:05,707 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2016-11-20 02:02:05,707 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-11-20 02:02:05,708 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2016-11-20 02:02:05,708 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2016-11-20 02:02:05,710 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2016-11-20 02:02:05,710 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-11-20 02:02:05,710 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2016-11-20 02:02:05,710 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2016-11-20 02:02:05,711 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2016-11-20 02:02:05,737 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2016-11-20 02:02:05,751 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2016-11-20 02:02:05,767 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2016-11-20 02:02:05,768 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2016-11-20 02:02:05,768 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-11-20 02:02:05,808 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2016-11-20 02:02:05,813 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2016-11-20 02:02:05,819 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2016-11-20 02:02:05,820 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-11-20 02:02:05,820 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2016-11-20 02:02:05,870 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2016-11-20 02:02:05,870 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2016-11-20 02:02:05,872 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2016-11-20 02:02:05,873 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-11-20 02:02:05,873 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2016-11-20 02:02:05,877 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2016-11-20 02:02:05,964 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-11-20 02:02:05,971 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-11-20 02:02:05,977 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2016-11-20 02:02:05,988 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-11-20 02:02:05,992 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2016-11-20 02:02:05,992 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2016-11-20 02:02:05,992 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2016-11-20 02:02:05,992 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2016-11-20 02:02:05,992 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-11-20 02:02:05,992 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-11-20 02:02:05,996 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2016-11-20 02:02:05,996 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2016-11-20 02:02:06,385 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2016-11-20 02:02:06,387 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2016-11-20 02:02:06,387 INFO org.mortbay.log: jetty-6.1.26
2016-11-20 02:02:06,413 INFO org.mortbay.log: Extract jar:file:/users/tanle/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar!/webapps/cluster to /tmp/Jetty_ctl_yarn.perf_yarnrm.pg0_utah_cloudlab_us_8088_cluster____.nwe3j9/webapp
2016-11-20 02:02:06,577 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-11-20 02:02:06,577 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2016-11-20 02:02:06,577 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2016-11-20 02:02:07,364 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@ctl.yarn-perf.yarnrm-pg0.utah.cloudlab.us:8088
2016-11-20 02:02:07,365 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2016-11-20 02:02:07,391 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2016-11-20 02:02:07,392 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2016-11-20 02:02:07,395 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2016-11-20 02:02:07,396 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2016-11-20 02:02:07,396 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-11-20 02:02:08,628 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us to /default-rack
2016-11-20 02:02:08,628 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us to /default-rack
2016-11-20 02:02:08,628 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us to /default-rack
2016-11-20 02:02:08,628 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us to /default-rack
2016-11-20 02:02:08,633 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us(cmPort: 38926 httpPort: 8042) registered with capability: <memory:32768, vCores:32>, assigned nodeId cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38926
2016-11-20 02:02:08,633 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us(cmPort: 45287 httpPort: 8042) registered with capability: <memory:32768, vCores:32>, assigned nodeId cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us:45287
2016-11-20 02:02:08,633 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us(cmPort: 46707 httpPort: 8042) registered with capability: <memory:32768, vCores:32>, assigned nodeId cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us:46707
2016-11-20 02:02:08,633 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us(cmPort: 38725 httpPort: 8042) registered with capability: <memory:32768, vCores:32>, assigned nodeId cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38725
2016-11-20 02:02:08,639 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38926 Node Transitioned from NEW to RUNNING
2016-11-20 02:02:08,640 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us:46707 Node Transitioned from NEW to RUNNING
2016-11-20 02:02:08,640 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38725 Node Transitioned from NEW to RUNNING
2016-11-20 02:02:08,640 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us:45287 Node Transitioned from NEW to RUNNING
2016-11-20 02:02:08,645 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Added node cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38926 cluster capacity: <memory:32768, vCores:32>
2016-11-20 02:02:08,646 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Added node cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us:46707 cluster capacity: <memory:65536, vCores:64>
2016-11-20 02:02:08,646 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Added node cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38725 cluster capacity: <memory:98304, vCores:96>
2016-11-20 02:02:08,646 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Added node cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us:45287 cluster capacity: <memory:131072, vCores:128>
2016-11-20 02:02:08,713 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us to /default-rack
2016-11-20 02:02:08,713 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us(cmPort: 38588 httpPort: 8042) registered with capability: <memory:32768, vCores:32>, assigned nodeId cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38588
2016-11-20 02:02:08,716 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38588 Node Transitioned from NEW to RUNNING
2016-11-20 02:02:08,728 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Added node cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38588 cluster capacity: <memory:163840, vCores:160>
2016-11-20 02:02:08,756 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us to /default-rack
2016-11-20 02:02:08,757 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us(cmPort: 33513 httpPort: 8042) registered with capability: <memory:32768, vCores:32>, assigned nodeId cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us:33513
2016-11-20 02:02:08,757 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us:33513 Node Transitioned from NEW to RUNNING
2016-11-20 02:02:08,758 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Added node cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us:33513 cluster capacity: <memory:196608, vCores:192>
2016-11-20 02:02:08,782 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us to /default-rack
2016-11-20 02:02:08,782 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us(cmPort: 36003 httpPort: 8042) registered with capability: <memory:32768, vCores:32>, assigned nodeId cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36003
2016-11-20 02:02:08,782 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36003 Node Transitioned from NEW to RUNNING
2016-11-20 02:02:08,784 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Added node cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36003 cluster capacity: <memory:229376, vCores:224>
2016-11-20 02:02:08,845 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us to /default-rack
2016-11-20 02:02:08,846 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us(cmPort: 36804 httpPort: 8042) registered with capability: <memory:32768, vCores:32>, assigned nodeId cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36804
2016-11-20 02:02:08,846 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36804 Node Transitioned from NEW to RUNNING
2016-11-20 02:02:08,847 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Added node cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36804 cluster capacity: <memory:262144, vCores:256>
2016-11-20 02:12:05,681 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Release request cache is cleaned up
2016-11-20 06:52:20,914 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 1
2016-11-20 06:52:23,215 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 1 submitted by user tanle
2016-11-20 06:52:23,216 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1479632525694_0001
2016-11-20 06:52:23,217 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	IP=128.110.153.236	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1479632525694_0001
2016-11-20 06:52:23,229 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1479632525694_0001
2016-11-20 06:52:23,346 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Accepted application application_1479632525694_0001 from user: tanle, in queue: bursty0, currently num of applications: 1
2016-11-20 06:52:23,396 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1479632525694_0001_000001
2016-11-20 06:52:23,397 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1479632525694_0001_000001 State change from NEW to SUBMITTED
2016-11-20 06:52:23,411 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Added Application Attempt appattempt_1479632525694_0001_000001 to scheduler from user: tanle
2016-11-20 06:52:23,412 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: ScheduleTransition.transition(appattempt_1479632525694_0001_000001,EventType: ATTEMPT_ADDED)
2016-11-20 06:52:23,413 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: allocate(appattempt_1479632525694_0001_000001 [{Priority: 0, Capability: <memory:2048, vCores:1>, # Containers: 1, Location: *, Relax Locality: true}] [] null null
2016-11-20 06:52:23,416 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1479632525694_0001_000001 State change from SUBMITTED to SCHEDULED
2016-11-20 06:52:23,655 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:0, vCores:0>
2016-11-20 06:52:23,655 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:0, vCores:0>
2016-11-20 06:52:23,798 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:23,810 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000001 priority 0
2016-11-20 06:52:23,819 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000001 of event START
2016-11-20 06:52:23,819 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000001 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:23,819 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000001
2016-11-20 06:52:23,820 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: AMContainerAllocatedTransition.transition(appattempt_1479632525694_0001_000001,EventType: CONTAINER_ALLOCATED)
2016-11-20 06:52:23,820 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000001 of capacity <memory:2048, vCores:1> on host cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us:46707, which has 1 containers, <memory:2048, vCores:1> used and <memory:30720, vCores:31> available after allocation
2016-11-20 06:52:23,820 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: allocate(appattempt_1479632525694_0001_000001 [] [] null null
2016-11-20 06:52:23,821 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:23,848 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us:46707 for container : container_1479632525694_0001_01_000001
2016-11-20 06:52:23,858 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000001 of event ACQUIRED
2016-11-20 06:52:23,859 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2016-11-20 06:52:23,860 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1479632525694_0001_000001
2016-11-20 06:52:23,860 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:23,860 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:23,861 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:23,861 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:23,861 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:23,861 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:23,863 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1479632525694_0001 AttemptId: appattempt_1479632525694_0001_000001 MasterContainer: Container: [ContainerId: container_1479632525694_0001_01_000001, NodeId: cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us:46707, NodeHttpAddress: cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 128.110.153.239:46707 }, ]
2016-11-20 06:52:23,877 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1479632525694_0001_000001 State change from SCHEDULED to ALLOCATED_SAVING
2016-11-20 06:52:23,878 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1479632525694_0001_000001 State change from ALLOCATED_SAVING to ALLOCATED
2016-11-20 06:52:23,881 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1479632525694_0001_000001
2016-11-20 06:52:23,913 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1479632525694_0001_01_000001, NodeId: cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us:46707, NodeHttpAddress: cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 128.110.153.239:46707 }, ] for AM appattempt_1479632525694_0001_000001
2016-11-20 06:52:23,913 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1479632525694_0001_01_000001 : $JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2016-11-20 06:52:23,916 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1479632525694_0001_000001
2016-11-20 06:52:23,919 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1479632525694_0001_000001
2016-11-20 06:52:24,156 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:2048, vCores:1>
2016-11-20 06:52:24,156 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:2048, vCores:1>
2016-11-20 06:52:24,293 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1479632525694_0001_01_000001, NodeId: cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us:46707, NodeHttpAddress: cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 128.110.153.239:46707 }, ] for AM appattempt_1479632525694_0001_000001
2016-11-20 06:52:24,294 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1479632525694_0001_000001 State change from ALLOCATED to LAUNCHED
2016-11-20 06:52:24,657 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:2048, vCores:1>
2016-11-20 06:52:24,657 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:2048, vCores:1>
2016-11-20 06:52:24,798 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:24,799 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:24,799 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:24,799 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:24,800 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:24,800 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:24,801 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:24,813 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000001 of event LAUNCHED
2016-11-20 06:52:24,813 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000001 Container Transitioned from ACQUIRED to RUNNING
2016-11-20 06:52:24,813 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:25,158 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:2048, vCores:1>
2016-11-20 06:52:25,158 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:2048, vCores:1>
2016-11-20 06:52:25,659 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:2048, vCores:1>
2016-11-20 06:52:25,659 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:2048, vCores:1>
2016-11-20 06:52:25,800 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:25,800 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:25,800 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:25,800 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:25,800 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:25,800 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:25,801 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:25,813 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:26,159 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:2048, vCores:1>
2016-11-20 06:52:26,159 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:2048, vCores:1>
2016-11-20 06:52:26,660 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:2048, vCores:1>
2016-11-20 06:52:26,660 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:2048, vCores:1>
2016-11-20 06:52:26,801 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:26,801 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:26,801 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:26,801 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:26,801 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:26,801 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:26,803 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:26,816 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:27,160 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:2048, vCores:1>
2016-11-20 06:52:27,161 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:2048, vCores:1>
2016-11-20 06:52:27,661 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:2048, vCores:1>
2016-11-20 06:52:27,661 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:2048, vCores:1>
2016-11-20 06:52:27,804 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:27,804 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:27,805 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:27,805 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:27,806 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:27,807 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:27,808 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:27,818 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:28,162 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:2048, vCores:1>
2016-11-20 06:52:28,162 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:2048, vCores:1>
2016-11-20 06:52:28,662 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:2048, vCores:1>
2016-11-20 06:52:28,662 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:2048, vCores:1>
2016-11-20 06:52:28,805 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:28,805 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:28,806 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:28,806 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:28,807 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:28,808 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:28,809 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:28,820 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:29,163 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:2048, vCores:1>
2016-11-20 06:52:29,164 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:2048, vCores:1>
2016-11-20 06:52:29,378 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1479632525694_0001_000001 (auth:SIMPLE)
2016-11-20 06:52:29,388 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1479632525694_0001_000001
2016-11-20 06:52:29,390 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	IP=128.110.153.239	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1479632525694_0001	APPATTEMPTID=appattempt_1479632525694_0001_000001
2016-11-20 06:52:29,390 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1479632525694_0001_000001 State change from LAUNCHED to RUNNING
2016-11-20 06:52:29,664 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:2048, vCores:1>
2016-11-20 06:52:29,664 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:2048, vCores:1>
2016-11-20 06:52:29,807 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:29,807 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:29,807 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:29,807 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:29,808 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:29,809 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:29,810 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:29,822 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:30,165 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:2048, vCores:1>
2016-11-20 06:52:30,165 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:2048, vCores:1>
2016-11-20 06:52:30,450 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: allocate(appattempt_1479632525694_0001_000001 [{Priority: 20, Capability: <memory:1536, vCores:1>, # Containers: 80, Location: *, Relax Locality: true}] [] [] []
2016-11-20 06:52:30,666 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:2048, vCores:1>
2016-11-20 06:52:30,666 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:2048, vCores:1>
2016-11-20 06:52:30,808 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:30,808 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000002 priority 20
2016-11-20 06:52:30,809 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000002 of event START
2016-11-20 06:52:30,809 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000002 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:30,809 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000002
2016-11-20 06:52:30,809 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000002 of capacity <memory:2048, vCores:1> on host cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38926, which has 1 containers, <memory:2048, vCores:1> used and <memory:30720, vCores:31> available after allocation
2016-11-20 06:52:30,809 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:30,810 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000003 priority 20
2016-11-20 06:52:30,810 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000003 of event START
2016-11-20 06:52:30,810 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000003 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:30,810 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000003
2016-11-20 06:52:30,811 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000003 of capacity <memory:2048, vCores:1> on host cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38588, which has 1 containers, <memory:2048, vCores:1> used and <memory:30720, vCores:31> available after allocation
2016-11-20 06:52:30,811 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:30,812 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000004 priority 20
2016-11-20 06:52:30,812 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000004 of event START
2016-11-20 06:52:30,812 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000004 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:30,812 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000004
2016-11-20 06:52:30,812 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000004 of capacity <memory:2048, vCores:1> on host cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36003, which has 1 containers, <memory:2048, vCores:1> used and <memory:30720, vCores:31> available after allocation
2016-11-20 06:52:30,812 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:30,813 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000005 priority 20
2016-11-20 06:52:30,813 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000005 of event START
2016-11-20 06:52:30,813 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000005 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:30,813 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000005
2016-11-20 06:52:30,814 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000005 of capacity <memory:2048, vCores:1> on host cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36804, which has 1 containers, <memory:2048, vCores:1> used and <memory:30720, vCores:31> available after allocation
2016-11-20 06:52:30,814 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:30,814 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000006 priority 20
2016-11-20 06:52:30,815 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000006 of event START
2016-11-20 06:52:30,815 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000006 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:30,815 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000006
2016-11-20 06:52:30,815 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000006 of capacity <memory:2048, vCores:1> on host cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us:45287, which has 1 containers, <memory:2048, vCores:1> used and <memory:30720, vCores:31> available after allocation
2016-11-20 06:52:30,816 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:30,816 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000007 priority 20
2016-11-20 06:52:30,816 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000007 of event START
2016-11-20 06:52:30,816 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000007 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:30,816 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000007
2016-11-20 06:52:30,816 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000007 of capacity <memory:2048, vCores:1> on host cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38725, which has 1 containers, <memory:2048, vCores:1> used and <memory:30720, vCores:31> available after allocation
2016-11-20 06:52:30,816 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:30,816 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000008 priority 20
2016-11-20 06:52:30,817 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000008 of event START
2016-11-20 06:52:30,817 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000008 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:30,817 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000008
2016-11-20 06:52:30,817 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000008 of capacity <memory:2048, vCores:1> on host cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us:33513, which has 1 containers, <memory:2048, vCores:1> used and <memory:30720, vCores:31> available after allocation
2016-11-20 06:52:30,823 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:30,824 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000009 priority 20
2016-11-20 06:52:30,824 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000009 of event START
2016-11-20 06:52:30,824 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000009 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:30,824 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000009
2016-11-20 06:52:30,824 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000009 of capacity <memory:2048, vCores:1> on host cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us:46707, which has 2 containers, <memory:4096, vCores:2> used and <memory:28672, vCores:30> available after allocation
2016-11-20 06:52:31,167 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:18432, vCores:9>
2016-11-20 06:52:31,167 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:18432, vCores:9>
2016-11-20 06:52:31,487 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: allocate(appattempt_1479632525694_0001_000001 [] [] [] []
2016-11-20 06:52:31,491 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38926 for container : container_1479632525694_0001_01_000002
2016-11-20 06:52:31,492 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000002 of event ACQUIRED
2016-11-20 06:52:31,493 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2016-11-20 06:52:31,494 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38588 for container : container_1479632525694_0001_01_000003
2016-11-20 06:52:31,494 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000003 of event ACQUIRED
2016-11-20 06:52:31,495 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2016-11-20 06:52:31,498 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36003 for container : container_1479632525694_0001_01_000004
2016-11-20 06:52:31,501 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000004 of event ACQUIRED
2016-11-20 06:52:31,501 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000004 Container Transitioned from ALLOCATED to ACQUIRED
2016-11-20 06:52:31,502 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36804 for container : container_1479632525694_0001_01_000005
2016-11-20 06:52:31,503 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000005 of event ACQUIRED
2016-11-20 06:52:31,503 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000005 Container Transitioned from ALLOCATED to ACQUIRED
2016-11-20 06:52:31,504 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us:45287 for container : container_1479632525694_0001_01_000006
2016-11-20 06:52:31,506 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000006 of event ACQUIRED
2016-11-20 06:52:31,506 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000006 Container Transitioned from ALLOCATED to ACQUIRED
2016-11-20 06:52:31,507 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38725 for container : container_1479632525694_0001_01_000007
2016-11-20 06:52:31,510 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000007 of event ACQUIRED
2016-11-20 06:52:31,510 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000007 Container Transitioned from ALLOCATED to ACQUIRED
2016-11-20 06:52:31,518 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us:33513 for container : container_1479632525694_0001_01_000008
2016-11-20 06:52:31,519 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000008 of event ACQUIRED
2016-11-20 06:52:31,519 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000008 Container Transitioned from ALLOCATED to ACQUIRED
2016-11-20 06:52:31,520 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us:46707 for container : container_1479632525694_0001_01_000009
2016-11-20 06:52:31,520 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000009 of event ACQUIRED
2016-11-20 06:52:31,521 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000009 Container Transitioned from ALLOCATED to ACQUIRED
2016-11-20 06:52:31,667 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:18432, vCores:9>
2016-11-20 06:52:31,667 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:18432, vCores:9>
2016-11-20 06:52:31,809 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:31,809 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000010 priority 20
2016-11-20 06:52:31,809 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000010 of event START
2016-11-20 06:52:31,809 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000010 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:31,809 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000010
2016-11-20 06:52:31,809 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000010 of capacity <memory:2048, vCores:1> on host cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38926, which has 2 containers, <memory:4096, vCores:2> used and <memory:28672, vCores:30> available after allocation
2016-11-20 06:52:31,810 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:31,810 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000011 priority 20
2016-11-20 06:52:31,810 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000011 of event START
2016-11-20 06:52:31,810 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000011 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:31,810 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000011
2016-11-20 06:52:31,810 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000011 of capacity <memory:2048, vCores:1> on host cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38588, which has 2 containers, <memory:4096, vCores:2> used and <memory:28672, vCores:30> available after allocation
2016-11-20 06:52:31,810 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:31,810 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000012 priority 20
2016-11-20 06:52:31,810 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000012 of event START
2016-11-20 06:52:31,810 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000012 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:31,810 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000012
2016-11-20 06:52:31,810 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000012 of capacity <memory:2048, vCores:1> on host cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36804, which has 2 containers, <memory:4096, vCores:2> used and <memory:28672, vCores:30> available after allocation
2016-11-20 06:52:31,811 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:31,811 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000013 priority 20
2016-11-20 06:52:31,812 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000013 of event START
2016-11-20 06:52:31,812 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000013 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:31,812 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000013
2016-11-20 06:52:31,812 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000013 of capacity <memory:2048, vCores:1> on host cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36003, which has 2 containers, <memory:4096, vCores:2> used and <memory:28672, vCores:30> available after allocation
2016-11-20 06:52:31,812 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:31,812 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000014 priority 20
2016-11-20 06:52:31,812 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000014 of event START
2016-11-20 06:52:31,812 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000014 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:31,812 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000014
2016-11-20 06:52:31,812 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000014 of capacity <memory:2048, vCores:1> on host cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us:45287, which has 2 containers, <memory:4096, vCores:2> used and <memory:28672, vCores:30> available after allocation
2016-11-20 06:52:31,812 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:31,812 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000015 priority 20
2016-11-20 06:52:31,813 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000015 of event START
2016-11-20 06:52:31,813 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000015 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:31,813 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000015
2016-11-20 06:52:31,813 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000015 of capacity <memory:2048, vCores:1> on host cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38725, which has 2 containers, <memory:4096, vCores:2> used and <memory:28672, vCores:30> available after allocation
2016-11-20 06:52:31,813 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:31,814 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000016 priority 20
2016-11-20 06:52:31,814 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000016 of event START
2016-11-20 06:52:31,814 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000016 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:31,814 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000016
2016-11-20 06:52:31,814 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000016 of capacity <memory:2048, vCores:1> on host cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us:33513, which has 2 containers, <memory:4096, vCores:2> used and <memory:28672, vCores:30> available after allocation
2016-11-20 06:52:31,825 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000009 of event LAUNCHED
2016-11-20 06:52:31,826 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000009 Container Transitioned from ACQUIRED to RUNNING
2016-11-20 06:52:31,826 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:31,826 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000017 priority 20
2016-11-20 06:52:31,826 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000017 of event START
2016-11-20 06:52:31,826 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000017 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:31,826 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000017
2016-11-20 06:52:31,826 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000017 of capacity <memory:2048, vCores:1> on host cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us:46707, which has 3 containers, <memory:6144, vCores:3> used and <memory:26624, vCores:29> available after allocation
2016-11-20 06:52:32,168 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:34816, vCores:17>
2016-11-20 06:52:32,168 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:34816, vCores:17>
2016-11-20 06:52:32,557 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: allocate(appattempt_1479632525694_0001_000001 [{Priority: 20, Capability: <memory:1536, vCores:1>, # Containers: 72, Location: *, Relax Locality: true}] [] [] []
2016-11-20 06:52:32,558 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000010 of event ACQUIRED
2016-11-20 06:52:32,559 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000010 Container Transitioned from ALLOCATED to ACQUIRED
2016-11-20 06:52:32,560 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000011 of event ACQUIRED
2016-11-20 06:52:32,560 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000011 Container Transitioned from ALLOCATED to ACQUIRED
2016-11-20 06:52:32,561 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000012 of event ACQUIRED
2016-11-20 06:52:32,562 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000012 Container Transitioned from ALLOCATED to ACQUIRED
2016-11-20 06:52:32,563 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000013 of event ACQUIRED
2016-11-20 06:52:32,563 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000013 Container Transitioned from ALLOCATED to ACQUIRED
2016-11-20 06:52:32,564 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000014 of event ACQUIRED
2016-11-20 06:52:32,565 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000014 Container Transitioned from ALLOCATED to ACQUIRED
2016-11-20 06:52:32,566 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000015 of event ACQUIRED
2016-11-20 06:52:32,566 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000015 Container Transitioned from ALLOCATED to ACQUIRED
2016-11-20 06:52:32,567 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000016 of event ACQUIRED
2016-11-20 06:52:32,568 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000016 Container Transitioned from ALLOCATED to ACQUIRED
2016-11-20 06:52:32,569 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000017 of event ACQUIRED
2016-11-20 06:52:32,570 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000017 Container Transitioned from ALLOCATED to ACQUIRED
2016-11-20 06:52:32,669 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:34816, vCores:17>
2016-11-20 06:52:32,669 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:34816, vCores:17>
2016-11-20 06:52:32,824 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000002 of event LAUNCHED
2016-11-20 06:52:32,824 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000002 Container Transitioned from ACQUIRED to RUNNING
2016-11-20 06:52:32,824 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000010 of event LAUNCHED
2016-11-20 06:52:32,825 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000010 Container Transitioned from ACQUIRED to RUNNING
2016-11-20 06:52:32,825 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:32,825 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000018 priority 20
2016-11-20 06:52:32,825 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000018 of event START
2016-11-20 06:52:32,825 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000018 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:32,825 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000018
2016-11-20 06:52:32,825 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000018 of capacity <memory:2048, vCores:1> on host cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38926, which has 3 containers, <memory:6144, vCores:3> used and <memory:26624, vCores:29> available after allocation
2016-11-20 06:52:32,826 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000007 of event LAUNCHED
2016-11-20 06:52:32,826 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000007 Container Transitioned from ACQUIRED to RUNNING
2016-11-20 06:52:32,827 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000015 of event LAUNCHED
2016-11-20 06:52:32,827 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000015 Container Transitioned from ACQUIRED to RUNNING
2016-11-20 06:52:32,827 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:32,827 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000019 priority 20
2016-11-20 06:52:32,827 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000019 of event START
2016-11-20 06:52:32,827 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000019 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:32,827 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000019
2016-11-20 06:52:32,827 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000019 of capacity <memory:2048, vCores:1> on host cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38725, which has 3 containers, <memory:6144, vCores:3> used and <memory:26624, vCores:29> available after allocation
2016-11-20 06:52:32,828 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000006 of event LAUNCHED
2016-11-20 06:52:32,828 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000006 Container Transitioned from ACQUIRED to RUNNING
2016-11-20 06:52:32,828 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000014 of event LAUNCHED
2016-11-20 06:52:32,828 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000014 Container Transitioned from ACQUIRED to RUNNING
2016-11-20 06:52:32,828 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:32,828 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000020 priority 20
2016-11-20 06:52:32,828 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000020 of event START
2016-11-20 06:52:32,828 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000020 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:32,828 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000020
2016-11-20 06:52:32,829 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000020 of capacity <memory:2048, vCores:1> on host cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us:45287, which has 3 containers, <memory:6144, vCores:3> used and <memory:26624, vCores:29> available after allocation
2016-11-20 06:52:32,829 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000004 of event LAUNCHED
2016-11-20 06:52:32,829 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000004 Container Transitioned from ACQUIRED to RUNNING
2016-11-20 06:52:32,829 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000013 of event LAUNCHED
2016-11-20 06:52:32,829 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000013 Container Transitioned from ACQUIRED to RUNNING
2016-11-20 06:52:32,829 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:32,829 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000021 priority 20
2016-11-20 06:52:32,829 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000021 of event START
2016-11-20 06:52:32,830 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000021 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:32,830 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000021
2016-11-20 06:52:32,830 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000021 of capacity <memory:2048, vCores:1> on host cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36003, which has 3 containers, <memory:6144, vCores:3> used and <memory:26624, vCores:29> available after allocation
2016-11-20 06:52:32,830 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000003 of event LAUNCHED
2016-11-20 06:52:32,830 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000003 Container Transitioned from ACQUIRED to RUNNING
2016-11-20 06:52:32,831 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000011 of event LAUNCHED
2016-11-20 06:52:32,831 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000011 Container Transitioned from ACQUIRED to RUNNING
2016-11-20 06:52:32,832 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:32,832 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000022 priority 20
2016-11-20 06:52:32,832 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000022 of event START
2016-11-20 06:52:32,832 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000022 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:32,832 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000022
2016-11-20 06:52:32,832 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000022 of capacity <memory:2048, vCores:1> on host cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38588, which has 3 containers, <memory:6144, vCores:3> used and <memory:26624, vCores:29> available after allocation
2016-11-20 06:52:32,832 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000017 of event LAUNCHED
2016-11-20 06:52:32,832 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000017 Container Transitioned from ACQUIRED to RUNNING
2016-11-20 06:52:32,832 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:32,832 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000023 priority 20
2016-11-20 06:52:32,833 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000023 of event START
2016-11-20 06:52:32,833 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000023 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:32,833 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000023
2016-11-20 06:52:32,833 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000023 of capacity <memory:2048, vCores:1> on host cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us:46707, which has 4 containers, <memory:8192, vCores:4> used and <memory:24576, vCores:28> available after allocation
2016-11-20 06:52:32,833 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000008 of event LAUNCHED
2016-11-20 06:52:32,833 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000008 Container Transitioned from ACQUIRED to RUNNING
2016-11-20 06:52:32,833 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000016 of event LAUNCHED
2016-11-20 06:52:32,833 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000016 Container Transitioned from ACQUIRED to RUNNING
2016-11-20 06:52:32,834 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:32,834 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000024 priority 20
2016-11-20 06:52:32,834 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000024 of event START
2016-11-20 06:52:32,834 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000024 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:32,834 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000024
2016-11-20 06:52:32,834 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000024 of capacity <memory:2048, vCores:1> on host cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us:33513, which has 3 containers, <memory:6144, vCores:3> used and <memory:26624, vCores:29> available after allocation
2016-11-20 06:52:32,834 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000005 of event LAUNCHED
2016-11-20 06:52:32,835 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000005 Container Transitioned from ACQUIRED to RUNNING
2016-11-20 06:52:32,835 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000012 of event LAUNCHED
2016-11-20 06:52:32,835 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000012 Container Transitioned from ACQUIRED to RUNNING
2016-11-20 06:52:32,835 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:32,835 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000025 priority 20
2016-11-20 06:52:32,835 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000025 of event START
2016-11-20 06:52:32,835 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000025 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:32,835 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000025
2016-11-20 06:52:32,835 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000025 of capacity <memory:2048, vCores:1> on host cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36804, which has 3 containers, <memory:6144, vCores:3> used and <memory:26624, vCores:29> available after allocation
2016-11-20 06:52:33,169 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:51200, vCores:25>
2016-11-20 06:52:33,170 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:51200, vCores:25>
2016-11-20 06:52:33,577 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: allocate(appattempt_1479632525694_0001_000001 [{Priority: 20, Capability: <memory:1536, vCores:1>, # Containers: 64, Location: *, Relax Locality: true}] [] [] []
2016-11-20 06:52:33,580 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000018 of event ACQUIRED
2016-11-20 06:52:33,582 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000018 Container Transitioned from ALLOCATED to ACQUIRED
2016-11-20 06:52:33,583 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000019 of event ACQUIRED
2016-11-20 06:52:33,583 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000019 Container Transitioned from ALLOCATED to ACQUIRED
2016-11-20 06:52:33,583 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000020 of event ACQUIRED
2016-11-20 06:52:33,583 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000020 Container Transitioned from ALLOCATED to ACQUIRED
2016-11-20 06:52:33,584 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000021 of event ACQUIRED
2016-11-20 06:52:33,584 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000021 Container Transitioned from ALLOCATED to ACQUIRED
2016-11-20 06:52:33,584 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000022 of event ACQUIRED
2016-11-20 06:52:33,584 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000022 Container Transitioned from ALLOCATED to ACQUIRED
2016-11-20 06:52:33,585 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000023 of event ACQUIRED
2016-11-20 06:52:33,585 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000023 Container Transitioned from ALLOCATED to ACQUIRED
2016-11-20 06:52:33,585 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000024 of event ACQUIRED
2016-11-20 06:52:33,585 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000024 Container Transitioned from ALLOCATED to ACQUIRED
2016-11-20 06:52:33,586 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000025 of event ACQUIRED
2016-11-20 06:52:33,586 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000025 Container Transitioned from ALLOCATED to ACQUIRED
2016-11-20 06:52:33,671 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:51200, vCores:25>
2016-11-20 06:52:33,671 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:51200, vCores:25>
2016-11-20 06:52:33,826 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000018 of event LAUNCHED
2016-11-20 06:52:33,828 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000018 Container Transitioned from ACQUIRED to RUNNING
2016-11-20 06:52:33,828 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:33,828 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000026 priority 20
2016-11-20 06:52:33,828 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000026 of event START
2016-11-20 06:52:33,828 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000026 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:33,828 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000026
2016-11-20 06:52:33,828 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000026 of capacity <memory:2048, vCores:1> on host cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38926, which has 4 containers, <memory:8192, vCores:4> used and <memory:24576, vCores:28> available after allocation
2016-11-20 06:52:33,829 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000019 of event LAUNCHED
2016-11-20 06:52:33,830 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000019 Container Transitioned from ACQUIRED to RUNNING
2016-11-20 06:52:33,830 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:33,830 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000027 priority 20
2016-11-20 06:52:33,830 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000027 of event START
2016-11-20 06:52:33,830 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000027 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:33,830 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000027
2016-11-20 06:52:33,830 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000027 of capacity <memory:2048, vCores:1> on host cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38725, which has 4 containers, <memory:8192, vCores:4> used and <memory:24576, vCores:28> available after allocation
2016-11-20 06:52:33,833 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000020 of event LAUNCHED
2016-11-20 06:52:33,833 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000020 Container Transitioned from ACQUIRED to RUNNING
2016-11-20 06:52:33,834 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:33,834 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000028 priority 20
2016-11-20 06:52:33,834 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000028 of event START
2016-11-20 06:52:33,834 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000028 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:33,834 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000028
2016-11-20 06:52:33,834 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000028 of capacity <memory:2048, vCores:1> on host cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us:45287, which has 4 containers, <memory:8192, vCores:4> used and <memory:24576, vCores:28> available after allocation
2016-11-20 06:52:33,834 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000021 of event LAUNCHED
2016-11-20 06:52:33,835 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000021 Container Transitioned from ACQUIRED to RUNNING
2016-11-20 06:52:33,835 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:33,835 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000029 priority 20
2016-11-20 06:52:33,835 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000029 of event START
2016-11-20 06:52:33,835 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000029 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:33,835 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000029
2016-11-20 06:52:33,835 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000029 of capacity <memory:2048, vCores:1> on host cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36003, which has 4 containers, <memory:8192, vCores:4> used and <memory:24576, vCores:28> available after allocation
2016-11-20 06:52:33,835 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000023 of event LAUNCHED
2016-11-20 06:52:33,836 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000023 Container Transitioned from ACQUIRED to RUNNING
2016-11-20 06:52:33,836 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:33,836 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000030 priority 20
2016-11-20 06:52:33,836 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000030 of event START
2016-11-20 06:52:33,836 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000030 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:33,836 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000030
2016-11-20 06:52:33,836 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000030 of capacity <memory:2048, vCores:1> on host cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us:46707, which has 5 containers, <memory:10240, vCores:5> used and <memory:22528, vCores:27> available after allocation
2016-11-20 06:52:33,836 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000025 of event LAUNCHED
2016-11-20 06:52:33,837 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000025 Container Transitioned from ACQUIRED to RUNNING
2016-11-20 06:52:33,837 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:33,837 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000031 priority 20
2016-11-20 06:52:33,837 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000031 of event START
2016-11-20 06:52:33,837 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000031 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:33,837 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000031
2016-11-20 06:52:33,837 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000031 of capacity <memory:2048, vCores:1> on host cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36804, which has 4 containers, <memory:8192, vCores:4> used and <memory:24576, vCores:28> available after allocation
2016-11-20 06:52:33,838 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000024 of event LAUNCHED
2016-11-20 06:52:33,839 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000024 Container Transitioned from ACQUIRED to RUNNING
2016-11-20 06:52:33,839 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:33,839 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000032 priority 20
2016-11-20 06:52:33,839 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000032 of event START
2016-11-20 06:52:33,839 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000032 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:33,839 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000032
2016-11-20 06:52:33,839 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000032 of capacity <memory:2048, vCores:1> on host cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us:33513, which has 4 containers, <memory:8192, vCores:4> used and <memory:24576, vCores:28> available after allocation
2016-11-20 06:52:33,840 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000022 of event LAUNCHED
2016-11-20 06:52:33,840 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000022 Container Transitioned from ACQUIRED to RUNNING
2016-11-20 06:52:33,840 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:33,840 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000033 priority 20
2016-11-20 06:52:33,840 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000033 of event START
2016-11-20 06:52:33,841 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000033 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:33,841 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000033
2016-11-20 06:52:33,841 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000033 of capacity <memory:2048, vCores:1> on host cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38588, which has 4 containers, <memory:8192, vCores:4> used and <memory:24576, vCores:28> available after allocation
2016-11-20 06:52:34,171 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:67584, vCores:33>
2016-11-20 06:52:34,171 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:67584, vCores:33>
2016-11-20 06:52:34,592 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: allocate(appattempt_1479632525694_0001_000001 [{Priority: 20, Capability: <memory:1536, vCores:1>, # Containers: 56, Location: *, Relax Locality: true}] [] [] []
2016-11-20 06:52:34,593 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000026 of event ACQUIRED
2016-11-20 06:52:34,595 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000026 Container Transitioned from ALLOCATED to ACQUIRED
2016-11-20 06:52:34,595 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000027 of event ACQUIRED
2016-11-20 06:52:34,596 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000027 Container Transitioned from ALLOCATED to ACQUIRED
2016-11-20 06:52:34,596 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000028 of event ACQUIRED
2016-11-20 06:52:34,596 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000028 Container Transitioned from ALLOCATED to ACQUIRED
2016-11-20 06:52:34,597 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000029 of event ACQUIRED
2016-11-20 06:52:34,597 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000029 Container Transitioned from ALLOCATED to ACQUIRED
2016-11-20 06:52:34,598 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000030 of event ACQUIRED
2016-11-20 06:52:34,598 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000030 Container Transitioned from ALLOCATED to ACQUIRED
2016-11-20 06:52:34,599 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000031 of event ACQUIRED
2016-11-20 06:52:34,600 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000031 Container Transitioned from ALLOCATED to ACQUIRED
2016-11-20 06:52:34,600 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000032 of event ACQUIRED
2016-11-20 06:52:34,600 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000032 Container Transitioned from ALLOCATED to ACQUIRED
2016-11-20 06:52:34,601 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000033 of event ACQUIRED
2016-11-20 06:52:34,601 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000033 Container Transitioned from ALLOCATED to ACQUIRED
2016-11-20 06:52:34,672 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:67584, vCores:33>
2016-11-20 06:52:34,672 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:67584, vCores:33>
2016-11-20 06:52:34,828 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000026 of event LAUNCHED
2016-11-20 06:52:34,828 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000026 Container Transitioned from ACQUIRED to RUNNING
2016-11-20 06:52:34,828 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:34,829 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000034 priority 20
2016-11-20 06:52:34,829 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000034 of event START
2016-11-20 06:52:34,829 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000034 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:34,829 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000034
2016-11-20 06:52:34,829 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000034 of capacity <memory:2048, vCores:1> on host cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38926, which has 5 containers, <memory:10240, vCores:5> used and <memory:22528, vCores:27> available after allocation
2016-11-20 06:52:34,830 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000028 of event LAUNCHED
2016-11-20 06:52:34,830 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000028 Container Transitioned from ACQUIRED to RUNNING
2016-11-20 06:52:34,831 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:34,831 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000035 priority 20
2016-11-20 06:52:34,831 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000035 of event START
2016-11-20 06:52:34,831 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000035 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:34,831 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000035
2016-11-20 06:52:34,831 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000035 of capacity <memory:2048, vCores:1> on host cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us:45287, which has 5 containers, <memory:10240, vCores:5> used and <memory:22528, vCores:27> available after allocation
2016-11-20 06:52:34,832 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000027 of event LAUNCHED
2016-11-20 06:52:34,832 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000027 Container Transitioned from ACQUIRED to RUNNING
2016-11-20 06:52:34,832 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:34,832 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000036 priority 20
2016-11-20 06:52:34,832 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000036 of event START
2016-11-20 06:52:34,832 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000036 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:34,832 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000036
2016-11-20 06:52:34,833 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000036 of capacity <memory:2048, vCores:1> on host cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38725, which has 5 containers, <memory:10240, vCores:5> used and <memory:22528, vCores:27> available after allocation
2016-11-20 06:52:34,833 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000029 of event LAUNCHED
2016-11-20 06:52:34,833 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000029 Container Transitioned from ACQUIRED to RUNNING
2016-11-20 06:52:34,833 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:34,833 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000037 priority 20
2016-11-20 06:52:34,834 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000037 of event START
2016-11-20 06:52:34,834 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000037 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:34,834 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000037
2016-11-20 06:52:34,834 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000037 of capacity <memory:2048, vCores:1> on host cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36003, which has 5 containers, <memory:10240, vCores:5> used and <memory:22528, vCores:27> available after allocation
2016-11-20 06:52:34,835 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000030 of event LAUNCHED
2016-11-20 06:52:34,835 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000030 Container Transitioned from ACQUIRED to RUNNING
2016-11-20 06:52:34,835 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:34,835 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000038 priority 20
2016-11-20 06:52:34,835 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000038 of event START
2016-11-20 06:52:34,835 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000038 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:34,835 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000038
2016-11-20 06:52:34,835 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000038 of capacity <memory:2048, vCores:1> on host cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us:46707, which has 6 containers, <memory:12288, vCores:6> used and <memory:20480, vCores:26> available after allocation
2016-11-20 06:52:34,836 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000031 of event LAUNCHED
2016-11-20 06:52:34,836 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000031 Container Transitioned from ACQUIRED to RUNNING
2016-11-20 06:52:34,836 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:34,836 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000039 priority 20
2016-11-20 06:52:34,836 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000039 of event START
2016-11-20 06:52:34,836 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000039 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:34,836 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000039
2016-11-20 06:52:34,836 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000039 of capacity <memory:2048, vCores:1> on host cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36804, which has 5 containers, <memory:10240, vCores:5> used and <memory:22528, vCores:27> available after allocation
2016-11-20 06:52:34,837 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000032 of event LAUNCHED
2016-11-20 06:52:34,837 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000032 Container Transitioned from ACQUIRED to RUNNING
2016-11-20 06:52:34,837 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:34,837 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000040 priority 20
2016-11-20 06:52:34,837 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000040 of event START
2016-11-20 06:52:34,837 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000040 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:34,837 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000040
2016-11-20 06:52:34,837 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000040 of capacity <memory:2048, vCores:1> on host cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us:33513, which has 5 containers, <memory:10240, vCores:5> used and <memory:22528, vCores:27> available after allocation
2016-11-20 06:52:34,838 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000033 of event LAUNCHED
2016-11-20 06:52:34,838 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000033 Container Transitioned from ACQUIRED to RUNNING
2016-11-20 06:52:34,838 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:34,838 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000041 priority 20
2016-11-20 06:52:34,838 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000041 of event START
2016-11-20 06:52:34,838 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000041 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:34,838 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000041
2016-11-20 06:52:34,838 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000041 of capacity <memory:2048, vCores:1> on host cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38588, which has 5 containers, <memory:10240, vCores:5> used and <memory:22528, vCores:27> available after allocation
2016-11-20 06:52:35,172 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:83968, vCores:41>
2016-11-20 06:52:35,173 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:83968, vCores:41>
2016-11-20 06:52:35,608 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: allocate(appattempt_1479632525694_0001_000001 [{Priority: 20, Capability: <memory:1536, vCores:1>, # Containers: 48, Location: *, Relax Locality: true}] [] [] []
2016-11-20 06:52:35,609 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000034 of event ACQUIRED
2016-11-20 06:52:35,610 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000034 Container Transitioned from ALLOCATED to ACQUIRED
2016-11-20 06:52:35,611 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000035 of event ACQUIRED
2016-11-20 06:52:35,611 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000035 Container Transitioned from ALLOCATED to ACQUIRED
2016-11-20 06:52:35,612 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000036 of event ACQUIRED
2016-11-20 06:52:35,612 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000036 Container Transitioned from ALLOCATED to ACQUIRED
2016-11-20 06:52:35,613 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000037 of event ACQUIRED
2016-11-20 06:52:35,615 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000037 Container Transitioned from ALLOCATED to ACQUIRED
2016-11-20 06:52:35,616 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000038 of event ACQUIRED
2016-11-20 06:52:35,616 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000038 Container Transitioned from ALLOCATED to ACQUIRED
2016-11-20 06:52:35,617 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000039 of event ACQUIRED
2016-11-20 06:52:35,617 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000039 Container Transitioned from ALLOCATED to ACQUIRED
2016-11-20 06:52:35,617 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000040 of event ACQUIRED
2016-11-20 06:52:35,617 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000040 Container Transitioned from ALLOCATED to ACQUIRED
2016-11-20 06:52:35,618 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000041 of event ACQUIRED
2016-11-20 06:52:35,618 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000041 Container Transitioned from ALLOCATED to ACQUIRED
2016-11-20 06:52:35,673 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:83968, vCores:41>
2016-11-20 06:52:35,674 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:83968, vCores:41>
2016-11-20 06:52:35,775 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000038 of event LAUNCHED
2016-11-20 06:52:35,775 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000038 Container Transitioned from ACQUIRED to RUNNING
2016-11-20 06:52:35,775 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:35,775 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000042 priority 20
2016-11-20 06:52:35,775 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000042 of event START
2016-11-20 06:52:35,775 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000042 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:35,775 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000042
2016-11-20 06:52:35,776 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000042 of capacity <memory:2048, vCores:1> on host cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us:46707, which has 7 containers, <memory:14336, vCores:7> used and <memory:18432, vCores:25> available after allocation
2016-11-20 06:52:35,832 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000034 of event LAUNCHED
2016-11-20 06:52:35,832 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000034 Container Transitioned from ACQUIRED to RUNNING
2016-11-20 06:52:35,832 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:35,832 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000043 priority 20
2016-11-20 06:52:35,832 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000043 of event START
2016-11-20 06:52:35,832 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000043 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:35,832 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000043
2016-11-20 06:52:35,832 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000043 of capacity <memory:2048, vCores:1> on host cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38926, which has 6 containers, <memory:12288, vCores:6> used and <memory:20480, vCores:26> available after allocation
2016-11-20 06:52:35,833 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000035 of event LAUNCHED
2016-11-20 06:52:35,833 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000035 Container Transitioned from ACQUIRED to RUNNING
2016-11-20 06:52:35,833 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:35,833 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000044 priority 20
2016-11-20 06:52:35,833 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000044 of event START
2016-11-20 06:52:35,833 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000044 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:35,833 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000044
2016-11-20 06:52:35,834 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000044 of capacity <memory:2048, vCores:1> on host cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us:45287, which has 6 containers, <memory:12288, vCores:6> used and <memory:20480, vCores:26> available after allocation
2016-11-20 06:52:35,835 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000037 of event LAUNCHED
2016-11-20 06:52:35,835 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000037 Container Transitioned from ACQUIRED to RUNNING
2016-11-20 06:52:35,835 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:35,835 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000045 priority 20
2016-11-20 06:52:35,835 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000045 of event START
2016-11-20 06:52:35,835 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000045 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:35,835 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000045
2016-11-20 06:52:35,835 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000045 of capacity <memory:2048, vCores:1> on host cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36003, which has 6 containers, <memory:12288, vCores:6> used and <memory:20480, vCores:26> available after allocation
2016-11-20 06:52:35,836 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000036 of event LAUNCHED
2016-11-20 06:52:35,836 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000036 Container Transitioned from ACQUIRED to RUNNING
2016-11-20 06:52:35,836 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:35,836 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000046 priority 20
2016-11-20 06:52:35,836 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000046 of event START
2016-11-20 06:52:35,836 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000046 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:35,836 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000046
2016-11-20 06:52:35,836 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000046 of capacity <memory:2048, vCores:1> on host cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38725, which has 6 containers, <memory:12288, vCores:6> used and <memory:20480, vCores:26> available after allocation
2016-11-20 06:52:35,837 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000039 of event LAUNCHED
2016-11-20 06:52:35,837 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000039 Container Transitioned from ACQUIRED to RUNNING
2016-11-20 06:52:35,837 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:35,837 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000047 priority 20
2016-11-20 06:52:35,837 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000047 of event START
2016-11-20 06:52:35,837 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000047 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:35,837 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000047
2016-11-20 06:52:35,837 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000047 of capacity <memory:2048, vCores:1> on host cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36804, which has 6 containers, <memory:12288, vCores:6> used and <memory:20480, vCores:26> available after allocation
2016-11-20 06:52:35,838 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000041 of event LAUNCHED
2016-11-20 06:52:35,838 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000041 Container Transitioned from ACQUIRED to RUNNING
2016-11-20 06:52:35,838 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:35,838 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000048 priority 20
2016-11-20 06:52:35,838 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000048 of event START
2016-11-20 06:52:35,838 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000048 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:35,838 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000048
2016-11-20 06:52:35,838 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000048 of capacity <memory:2048, vCores:1> on host cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38588, which has 6 containers, <memory:12288, vCores:6> used and <memory:20480, vCores:26> available after allocation
2016-11-20 06:52:35,839 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000040 of event LAUNCHED
2016-11-20 06:52:35,839 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000040 Container Transitioned from ACQUIRED to RUNNING
2016-11-20 06:52:35,839 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:35,839 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000049 priority 20
2016-11-20 06:52:35,840 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000049 of event START
2016-11-20 06:52:35,840 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000049 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:35,840 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000049
2016-11-20 06:52:35,840 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000049 of capacity <memory:2048, vCores:1> on host cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us:33513, which has 6 containers, <memory:12288, vCores:6> used and <memory:20480, vCores:26> available after allocation
2016-11-20 06:52:36,174 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:100352, vCores:49>
2016-11-20 06:52:36,174 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:100352, vCores:49>
2016-11-20 06:52:36,675 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:100352, vCores:49>
2016-11-20 06:52:36,675 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:100352, vCores:49>
2016-11-20 06:52:36,833 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:36,833 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000050 priority 20
2016-11-20 06:52:36,833 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000050 of event START
2016-11-20 06:52:36,833 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000050 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:36,833 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000050
2016-11-20 06:52:36,833 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000050 of capacity <memory:2048, vCores:1> on host cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38926, which has 7 containers, <memory:14336, vCores:7> used and <memory:18432, vCores:25> available after allocation
2016-11-20 06:52:36,834 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:36,834 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000051 priority 20
2016-11-20 06:52:36,834 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000051 of event START
2016-11-20 06:52:36,834 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000051 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:36,834 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000051
2016-11-20 06:52:36,834 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000051 of capacity <memory:2048, vCores:1> on host cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us:45287, which has 7 containers, <memory:14336, vCores:7> used and <memory:18432, vCores:25> available after allocation
2016-11-20 06:52:36,836 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:36,836 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000052 priority 20
2016-11-20 06:52:36,836 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000052 of event START
2016-11-20 06:52:36,836 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000052 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:36,836 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000052
2016-11-20 06:52:36,836 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000052 of capacity <memory:2048, vCores:1> on host cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36003, which has 7 containers, <memory:14336, vCores:7> used and <memory:18432, vCores:25> available after allocation
2016-11-20 06:52:36,836 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:36,836 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000053 priority 20
2016-11-20 06:52:36,836 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000053 of event START
2016-11-20 06:52:36,836 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000053 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:36,836 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000053
2016-11-20 06:52:36,836 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000053 of capacity <memory:2048, vCores:1> on host cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38725, which has 7 containers, <memory:14336, vCores:7> used and <memory:18432, vCores:25> available after allocation
2016-11-20 06:52:36,836 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:36,837 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000054 priority 20
2016-11-20 06:52:36,837 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000054 of event START
2016-11-20 06:52:36,837 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000054 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:36,837 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000054
2016-11-20 06:52:36,837 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000054 of capacity <memory:2048, vCores:1> on host cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36804, which has 7 containers, <memory:14336, vCores:7> used and <memory:18432, vCores:25> available after allocation
2016-11-20 06:52:36,839 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:36,839 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000055 priority 20
2016-11-20 06:52:36,840 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000055 of event START
2016-11-20 06:52:36,840 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000055 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:36,840 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000055
2016-11-20 06:52:36,840 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000055 of capacity <memory:2048, vCores:1> on host cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38588, which has 7 containers, <memory:14336, vCores:7> used and <memory:18432, vCores:25> available after allocation
2016-11-20 06:52:36,841 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:36,841 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000056 priority 20
2016-11-20 06:52:36,841 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000056 of event START
2016-11-20 06:52:36,841 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000056 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:36,841 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000056
2016-11-20 06:52:36,841 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000056 of capacity <memory:2048, vCores:1> on host cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us:33513, which has 7 containers, <memory:14336, vCores:7> used and <memory:18432, vCores:25> available after allocation
2016-11-20 06:52:37,175 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:114688, vCores:56>
2016-11-20 06:52:37,175 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:114688, vCores:56>
2016-11-20 06:52:37,676 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:114688, vCores:56>
2016-11-20 06:52:37,676 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:114688, vCores:56>
2016-11-20 06:52:37,835 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:37,835 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000057 priority 20
2016-11-20 06:52:37,835 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000057 of event START
2016-11-20 06:52:37,836 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000057 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:37,836 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000057
2016-11-20 06:52:37,836 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000057 of capacity <memory:2048, vCores:1> on host cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38926, which has 8 containers, <memory:16384, vCores:8> used and <memory:16384, vCores:24> available after allocation
2016-11-20 06:52:37,836 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:37,836 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000058 priority 20
2016-11-20 06:52:37,836 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000058 of event START
2016-11-20 06:52:37,836 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000058 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:37,836 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000058
2016-11-20 06:52:37,836 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000058 of capacity <memory:2048, vCores:1> on host cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us:45287, which has 8 containers, <memory:16384, vCores:8> used and <memory:16384, vCores:24> available after allocation
2016-11-20 06:52:37,837 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:37,837 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000059 priority 20
2016-11-20 06:52:37,838 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000059 of event START
2016-11-20 06:52:37,838 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000059 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:37,838 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000059
2016-11-20 06:52:37,838 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000059 of capacity <memory:2048, vCores:1> on host cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38725, which has 8 containers, <memory:16384, vCores:8> used and <memory:16384, vCores:24> available after allocation
2016-11-20 06:52:37,838 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:37,838 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000060 priority 20
2016-11-20 06:52:37,838 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000060 of event START
2016-11-20 06:52:37,838 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000060 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:37,838 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000060
2016-11-20 06:52:37,838 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000060 of capacity <memory:2048, vCores:1> on host cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36003, which has 8 containers, <memory:16384, vCores:8> used and <memory:16384, vCores:24> available after allocation
2016-11-20 06:52:37,838 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:37,838 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000061 priority 20
2016-11-20 06:52:37,838 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000061 of event START
2016-11-20 06:52:37,838 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000061 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:37,839 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000061
2016-11-20 06:52:37,839 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000061 of capacity <memory:2048, vCores:1> on host cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36804, which has 8 containers, <memory:16384, vCores:8> used and <memory:16384, vCores:24> available after allocation
2016-11-20 06:52:37,841 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:37,841 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000062 priority 20
2016-11-20 06:52:37,841 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000062 of event START
2016-11-20 06:52:37,842 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000062 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:37,842 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000062
2016-11-20 06:52:37,842 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000062 of capacity <memory:2048, vCores:1> on host cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38588, which has 8 containers, <memory:16384, vCores:8> used and <memory:16384, vCores:24> available after allocation
2016-11-20 06:52:37,842 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:37,842 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000063 priority 20
2016-11-20 06:52:37,843 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000063 of event START
2016-11-20 06:52:37,843 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000063 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:37,843 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000063
2016-11-20 06:52:37,843 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000063 of capacity <memory:2048, vCores:1> on host cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us:33513, which has 8 containers, <memory:16384, vCores:8> used and <memory:16384, vCores:24> available after allocation
2016-11-20 06:52:38,176 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:129024, vCores:63>
2016-11-20 06:52:38,176 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:129024, vCores:63>
2016-11-20 06:52:38,677 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:129024, vCores:63>
2016-11-20 06:52:38,677 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:129024, vCores:63>
2016-11-20 06:52:38,836 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:38,837 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000064 priority 20
2016-11-20 06:52:38,837 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000064 of event START
2016-11-20 06:52:38,837 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000064 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:38,837 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000064
2016-11-20 06:52:38,837 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000064 of capacity <memory:2048, vCores:1> on host cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38926, which has 9 containers, <memory:18432, vCores:9> used and <memory:14336, vCores:23> available after allocation
2016-11-20 06:52:38,837 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:38,837 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000065 priority 20
2016-11-20 06:52:38,838 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000065 of event START
2016-11-20 06:52:38,838 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000065 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:38,838 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000065
2016-11-20 06:52:38,838 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000065 of capacity <memory:2048, vCores:1> on host cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us:45287, which has 9 containers, <memory:18432, vCores:9> used and <memory:14336, vCores:23> available after allocation
2016-11-20 06:52:38,839 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:38,839 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000066 priority 20
2016-11-20 06:52:38,840 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000066 of event START
2016-11-20 06:52:38,840 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000066 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:38,840 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000066
2016-11-20 06:52:38,840 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000066 of capacity <memory:2048, vCores:1> on host cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36804, which has 9 containers, <memory:18432, vCores:9> used and <memory:14336, vCores:23> available after allocation
2016-11-20 06:52:38,840 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:38,840 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000067 priority 20
2016-11-20 06:52:38,840 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000067 of event START
2016-11-20 06:52:38,840 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000067 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:38,840 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000067
2016-11-20 06:52:38,840 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000067 of capacity <memory:2048, vCores:1> on host cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38725, which has 9 containers, <memory:18432, vCores:9> used and <memory:14336, vCores:23> available after allocation
2016-11-20 06:52:38,840 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:38,841 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000068 priority 20
2016-11-20 06:52:38,841 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000068 of event START
2016-11-20 06:52:38,842 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000068 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:38,842 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000068
2016-11-20 06:52:38,842 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000068 of capacity <memory:2048, vCores:1> on host cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36003, which has 9 containers, <memory:18432, vCores:9> used and <memory:14336, vCores:23> available after allocation
2016-11-20 06:52:38,844 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:38,844 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000069 priority 20
2016-11-20 06:52:38,844 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000069 of event START
2016-11-20 06:52:38,844 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000069 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:38,844 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000069
2016-11-20 06:52:38,845 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000069 of capacity <memory:2048, vCores:1> on host cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38588, which has 9 containers, <memory:18432, vCores:9> used and <memory:14336, vCores:23> available after allocation
2016-11-20 06:52:38,845 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:38,845 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000070 priority 20
2016-11-20 06:52:38,845 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000070 of event START
2016-11-20 06:52:38,845 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000070 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:38,845 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000070
2016-11-20 06:52:38,845 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000070 of capacity <memory:2048, vCores:1> on host cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us:33513, which has 9 containers, <memory:18432, vCores:9> used and <memory:14336, vCores:23> available after allocation
2016-11-20 06:52:39,177 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:143360, vCores:70>
2016-11-20 06:52:39,177 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:143360, vCores:70>
2016-11-20 06:52:39,678 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:143360, vCores:70>
2016-11-20 06:52:39,678 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:143360, vCores:70>
2016-11-20 06:52:39,839 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:39,839 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000071 priority 20
2016-11-20 06:52:39,839 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000071 of event START
2016-11-20 06:52:39,839 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000071 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:39,839 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000071
2016-11-20 06:52:39,839 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000071 of capacity <memory:2048, vCores:1> on host cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38926, which has 10 containers, <memory:20480, vCores:10> used and <memory:12288, vCores:22> available after allocation
2016-11-20 06:52:39,839 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:39,839 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000072 priority 20
2016-11-20 06:52:39,839 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000072 of event START
2016-11-20 06:52:39,839 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000072 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:39,839 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000072
2016-11-20 06:52:39,840 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000072 of capacity <memory:2048, vCores:1> on host cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us:45287, which has 10 containers, <memory:20480, vCores:10> used and <memory:12288, vCores:22> available after allocation
2016-11-20 06:52:39,841 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:39,841 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000073 priority 20
2016-11-20 06:52:39,841 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000073 of event START
2016-11-20 06:52:39,841 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000073 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:39,841 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000073
2016-11-20 06:52:39,842 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000073 of capacity <memory:2048, vCores:1> on host cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36804, which has 10 containers, <memory:20480, vCores:10> used and <memory:12288, vCores:22> available after allocation
2016-11-20 06:52:39,843 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:39,843 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000074 priority 20
2016-11-20 06:52:39,843 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000074 of event START
2016-11-20 06:52:39,843 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000074 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:39,843 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000074
2016-11-20 06:52:39,843 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000074 of capacity <memory:2048, vCores:1> on host cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36003, which has 10 containers, <memory:20480, vCores:10> used and <memory:12288, vCores:22> available after allocation
2016-11-20 06:52:39,844 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:39,844 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000075 priority 20
2016-11-20 06:52:39,844 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000075 of event START
2016-11-20 06:52:39,844 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000075 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:39,844 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000075
2016-11-20 06:52:39,844 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000075 of capacity <memory:2048, vCores:1> on host cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38725, which has 10 containers, <memory:20480, vCores:10> used and <memory:12288, vCores:22> available after allocation
2016-11-20 06:52:39,846 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:39,846 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000076 priority 20
2016-11-20 06:52:39,846 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000076 of event START
2016-11-20 06:52:39,846 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000076 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:39,847 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000076
2016-11-20 06:52:39,847 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000076 of capacity <memory:2048, vCores:1> on host cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38588, which has 10 containers, <memory:20480, vCores:10> used and <memory:12288, vCores:22> available after allocation
2016-11-20 06:52:39,847 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:39,847 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000077 priority 20
2016-11-20 06:52:39,847 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000077 of event START
2016-11-20 06:52:39,847 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000077 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:39,847 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000077
2016-11-20 06:52:39,847 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000077 of capacity <memory:2048, vCores:1> on host cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us:33513, which has 10 containers, <memory:20480, vCores:10> used and <memory:12288, vCores:22> available after allocation
2016-11-20 06:52:40,178 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:157696, vCores:77>
2016-11-20 06:52:40,178 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:157696, vCores:77>
2016-11-20 06:52:40,679 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:157696, vCores:77>
2016-11-20 06:52:40,679 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:157696, vCores:77>
2016-11-20 06:52:40,840 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:40,841 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000078 priority 20
2016-11-20 06:52:40,841 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000078 of event START
2016-11-20 06:52:40,841 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000078 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:40,841 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000078
2016-11-20 06:52:40,841 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000078 of capacity <memory:2048, vCores:1> on host cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38926, which has 11 containers, <memory:22528, vCores:11> used and <memory:10240, vCores:21> available after allocation
2016-11-20 06:52:40,841 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:40,841 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000079 priority 20
2016-11-20 06:52:40,841 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000079 of event START
2016-11-20 06:52:40,841 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000079 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:40,841 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000079
2016-11-20 06:52:40,841 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000079 of capacity <memory:2048, vCores:1> on host cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us:45287, which has 11 containers, <memory:22528, vCores:11> used and <memory:10240, vCores:21> available after allocation
2016-11-20 06:52:40,843 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:40,843 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000080 priority 20
2016-11-20 06:52:40,844 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000080 of event START
2016-11-20 06:52:40,844 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000080 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:40,844 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000080
2016-11-20 06:52:40,844 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000080 of capacity <memory:2048, vCores:1> on host cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36804, which has 11 containers, <memory:22528, vCores:11> used and <memory:10240, vCores:21> available after allocation
2016-11-20 06:52:40,844 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:40,844 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000081 priority 20
2016-11-20 06:52:40,844 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000081 of event START
2016-11-20 06:52:40,844 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000081 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:40,844 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000081
2016-11-20 06:52:40,844 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000081 of capacity <memory:2048, vCores:1> on host cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36003, which has 11 containers, <memory:22528, vCores:11> used and <memory:10240, vCores:21> available after allocation
2016-11-20 06:52:40,844 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:40,844 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000082 priority 20
2016-11-20 06:52:40,844 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000082 of event START
2016-11-20 06:52:40,844 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000082 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:40,845 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000082
2016-11-20 06:52:40,845 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000082 of capacity <memory:2048, vCores:1> on host cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38725, which has 11 containers, <memory:22528, vCores:11> used and <memory:10240, vCores:21> available after allocation
2016-11-20 06:52:40,848 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:40,848 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000083 priority 20
2016-11-20 06:52:40,848 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000083 of event START
2016-11-20 06:52:40,848 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000083 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:40,848 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000083
2016-11-20 06:52:40,848 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000083 of capacity <memory:2048, vCores:1> on host cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38588, which has 11 containers, <memory:22528, vCores:11> used and <memory:10240, vCores:21> available after allocation
2016-11-20 06:52:40,848 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:40,848 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000084 priority 20
2016-11-20 06:52:40,848 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000084 of event START
2016-11-20 06:52:40,848 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000084 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:40,848 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000084
2016-11-20 06:52:40,849 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000084 of capacity <memory:2048, vCores:1> on host cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us:33513, which has 11 containers, <memory:22528, vCores:11> used and <memory:10240, vCores:21> available after allocation
2016-11-20 06:52:41,179 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:172032, vCores:84>
2016-11-20 06:52:41,179 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:172032, vCores:84>
2016-11-20 06:52:41,679 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:172032, vCores:84>
2016-11-20 06:52:41,680 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:172032, vCores:84>
2016-11-20 06:52:41,842 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:41,842 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000085 priority 20
2016-11-20 06:52:41,842 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000085 of event START
2016-11-20 06:52:41,842 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000085 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:41,842 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000085
2016-11-20 06:52:41,843 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000085 of capacity <memory:2048, vCores:1> on host cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us:45287, which has 12 containers, <memory:24576, vCores:12> used and <memory:8192, vCores:20> available after allocation
2016-11-20 06:52:41,843 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:41,843 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000086 priority 20
2016-11-20 06:52:41,843 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000086 of event START
2016-11-20 06:52:41,843 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000086 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:41,843 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000086
2016-11-20 06:52:41,843 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000086 of capacity <memory:2048, vCores:1> on host cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38926, which has 12 containers, <memory:24576, vCores:12> used and <memory:8192, vCores:20> available after allocation
2016-11-20 06:52:41,845 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:41,845 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000087 priority 20
2016-11-20 06:52:41,845 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000087 of event START
2016-11-20 06:52:41,845 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000087 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:41,845 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000087
2016-11-20 06:52:41,845 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000087 of capacity <memory:2048, vCores:1> on host cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36804, which has 12 containers, <memory:24576, vCores:12> used and <memory:8192, vCores:20> available after allocation
2016-11-20 06:52:41,845 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:41,845 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000088 priority 20
2016-11-20 06:52:41,845 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000088 of event START
2016-11-20 06:52:41,845 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000088 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:41,846 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000088
2016-11-20 06:52:41,846 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000088 of capacity <memory:2048, vCores:1> on host cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36003, which has 12 containers, <memory:24576, vCores:12> used and <memory:8192, vCores:20> available after allocation
2016-11-20 06:52:41,846 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:41,846 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: allocate container: container_1479632525694_0001_01_000089 priority 20
2016-11-20 06:52:41,846 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000089 of event START
2016-11-20 06:52:41,846 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000089 Container Transitioned from NEW to ALLOCATED
2016-11-20 06:52:41,846 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000089
2016-11-20 06:52:41,846 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1479632525694_0001_01_000089 of capacity <memory:2048, vCores:1> on host cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38725, which has 12 containers, <memory:24576, vCores:12> used and <memory:8192, vCores:20> available after allocation
2016-11-20 06:52:41,849 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:41,849 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:42,180 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:42,180 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:42,680 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:42,680 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:42,844 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:42,844 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:42,846 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:42,846 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:42,846 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:42,850 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:42,850 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:43,181 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:43,181 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:43,681 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:43,681 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:43,846 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:43,846 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:43,848 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:43,848 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:43,848 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:43,852 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:43,854 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:44,181 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:44,181 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:44,682 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:44,682 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:44,848 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:44,848 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:44,850 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:44,850 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:44,850 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:44,853 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:44,855 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:45,182 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:45,182 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:45,683 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:45,683 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:45,849 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:45,850 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:45,851 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:45,852 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:45,852 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:45,855 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:45,857 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: assignContainer(FSSchedulerNode node:cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us, boolean reserved=false) for appattempt_1479632525694_0001_000001
2016-11-20 06:52:46,183 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:46,183 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:46,684 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:46,684 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:47,184 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:47,184 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:47,684 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:47,684 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:48,185 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:48,185 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:48,685 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:48,685 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:49,186 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:49,186 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:49,686 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:49,686 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:50,186 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:50,186 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:50,687 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:50,687 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:51,187 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:51,187 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:51,687 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:51,687 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:52,188 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:52,188 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:52,688 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:52,688 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:53,188 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:53,189 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:53,689 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:53,689 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:54,189 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:54,189 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:54,690 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:54,690 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:55,190 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:55,190 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:55,691 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:55,691 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:56,191 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:56,191 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:56,691 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:56,691 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:57,192 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:57,192 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:57,692 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:57,692 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:58,192 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:58,192 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:58,693 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:58,693 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:59,193 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:59,193 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:59,693 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:52:59,693 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:00,194 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:00,194 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:00,694 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:00,694 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:01,194 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:01,194 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:01,695 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:01,696 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:02,196 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:02,196 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:02,696 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:02,696 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:03,197 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:03,197 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:03,697 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:03,697 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:04,197 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:04,197 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:04,698 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:04,698 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:05,198 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:05,198 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:05,699 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:05,699 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:06,199 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:06,199 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:06,699 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:06,700 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:07,200 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:07,200 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:07,700 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:07,700 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:08,201 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:08,201 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:08,701 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:08,701 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:09,201 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:09,201 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:09,702 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:09,702 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:10,202 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:10,202 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:10,703 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:10,703 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:11,203 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:11,204 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:11,704 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:11,704 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:12,204 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:12,204 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:12,704 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:12,705 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:13,205 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:13,205 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:13,705 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:13,705 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:14,206 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:14,206 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:14,706 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:14,706 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:15,206 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:15,207 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:15,707 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:15,707 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:16,207 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:16,207 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:16,708 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:16,708 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:17,208 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:17,208 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:17,708 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:17,708 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:18,208 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:18,209 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:18,709 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:18,709 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:19,209 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:19,209 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:19,709 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:19,710 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:20,210 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:20,210 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:20,710 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:20,710 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:21,211 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:21,211 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:21,711 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:21,711 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:22,211 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:22,211 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:22,712 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:22,712 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:23,212 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:23,212 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:23,712 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:23,713 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:24,213 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:24,213 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:24,713 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:24,713 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:25,214 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:25,214 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:25,714 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:25,714 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:26,214 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:26,214 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:26,715 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:26,715 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:27,216 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:27,216 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:27,716 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:27,716 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:28,216 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:28,216 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:28,717 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:28,717 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:29,217 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:29,217 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:29,717 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:29,717 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:30,218 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:30,218 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:30,718 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:30,718 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:31,219 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:31,219 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:31,719 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:31,719 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:32,219 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:32,219 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:32,720 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:32,720 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:33,220 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:33,220 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:33,720 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:33,720 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:34,221 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:34,221 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:34,721 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:34,721 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:35,221 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:35,221 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:35,722 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:35,722 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:36,222 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:36,222 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:36,722 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:36,722 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:37,222 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:37,223 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:37,723 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:37,723 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:38,223 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:38,223 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:38,723 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:38,723 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:39,224 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:39,224 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:39,724 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:39,724 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:40,224 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:40,225 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:40,725 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:40,725 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:41,225 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:41,225 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:41,725 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:41,725 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:42,226 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:42,226 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:42,726 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:42,726 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:43,226 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:43,226 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:43,727 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:43,727 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:44,227 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:44,227 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:44,727 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:44,727 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:45,227 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:45,228 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:45,728 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:45,728 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:46,228 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:46,228 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:46,728 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:46,728 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:47,229 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:47,229 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:47,729 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:47,729 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:48,229 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:48,230 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:48,730 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:48,730 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:49,230 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:49,231 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:49,731 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:49,731 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:50,231 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:50,231 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:50,731 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:50,732 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:51,232 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:51,232 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:51,732 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:51,732 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares: sched: root.bursty0 resource: <memory:182272, vCores:89>
2016-11-20 06:53:51,986 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1479632525694_0001_000001 with final state: KILLED, and exit status: -1000
2016-11-20 06:53:51,987 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1479632525694_0001_000001 State change from RUNNING to FINAL_SAVING
2016-11-20 06:53:51,988 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1479632525694_0001_000001
2016-11-20 06:53:51,989 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1479632525694_0001_000001
2016-11-20 06:53:51,989 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1479632525694_0001_000001 State change from FINAL_SAVING to KILLED
2016-11-20 06:53:51,989 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1479632525694_0001 with final state: KILLED
2016-11-20 06:53:51,990 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application appattempt_1479632525694_0001_000001 is done. finalState=KILLED
2016-11-20 06:53:51,990 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1479632525694_0001
2016-11-20 06:53:51,990 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1479632525694_0001_000001
2016-11-20 06:53:51,994 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000002 of event KILL
2016-11-20 06:53:51,994 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=Application Finished - Killed	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1479632525694_0001
2016-11-20 06:53:51,995 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000002 Container Transitioned from RUNNING to KILLED
2016-11-20 06:53:51,995 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000002 in state: KILLED event:KILL
2016-11-20 06:53:51,995 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000002
2016-11-20 06:53:51,995 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000002 of capacity <memory:2048, vCores:1> on host cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38926, which currently has 11 containers, <memory:22528, vCores:11> used and <memory:10240, vCores:21> available, release resources=true
2016-11-20 06:53:51,995 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000002 on node: host: cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38926 #containers=11 available=<memory:10240, vCores:21> used=<memory:22528, vCores:11> with event: KILL
2016-11-20 06:53:51,995 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000031 of event KILL
2016-11-20 06:53:51,995 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000031 Container Transitioned from RUNNING to KILLED
2016-11-20 06:53:51,995 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000031 in state: KILLED event:KILL
2016-11-20 06:53:51,996 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000031
2016-11-20 06:53:51,996 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000031 of capacity <memory:2048, vCores:1> on host cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36804, which currently has 11 containers, <memory:22528, vCores:11> used and <memory:10240, vCores:21> available, release resources=true
2016-11-20 06:53:51,996 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000031 on node: host: cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36804 #containers=11 available=<memory:10240, vCores:21> used=<memory:22528, vCores:11> with event: KILL
2016-11-20 06:53:51,996 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000064 of event KILL
2016-11-20 06:53:51,996 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000064 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:51,996 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000064 in state: KILLED event:KILL
2016-11-20 06:53:51,996 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000064
2016-11-20 06:53:51,996 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000064 of capacity <memory:2048, vCores:1> on host cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38926, which currently has 10 containers, <memory:20480, vCores:10> used and <memory:12288, vCores:22> available, release resources=true
2016-11-20 06:53:51,996 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000064 on node: host: cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38926 #containers=10 available=<memory:12288, vCores:22> used=<memory:20480, vCores:10> with event: KILL
2016-11-20 06:53:51,996 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000006 of event KILL
2016-11-20 06:53:51,996 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000006 Container Transitioned from RUNNING to KILLED
2016-11-20 06:53:51,996 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000006 in state: KILLED event:KILL
2016-11-20 06:53:51,996 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000006
2016-11-20 06:53:51,996 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000006 of capacity <memory:2048, vCores:1> on host cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us:45287, which currently has 11 containers, <memory:22528, vCores:11> used and <memory:10240, vCores:21> available, release resources=true
2016-11-20 06:53:51,996 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000006 on node: host: cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us:45287 #containers=11 available=<memory:10240, vCores:21> used=<memory:22528, vCores:11> with event: KILL
2016-11-20 06:53:51,996 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000035 of event KILL
2016-11-20 06:53:51,996 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000035 Container Transitioned from RUNNING to KILLED
2016-11-20 06:53:51,996 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1479632525694_0001,name=hdfsWrite,user=tanle,queue=root.bursty0,state=KILLED,trackingUrl=http://ctl.yarn-perf.yarnrm-pg0.utah.cloudlab.us:8088/cluster/app/application_1479632525694_0001,appMasterHost=N/A,startTime=1479649943214,finishTime=1479650031989,finalStatus=KILLED,memorySeconds=13876281,vcoreSeconds=6761,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2016-11-20 06:53:51,996 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000035 in state: KILLED event:KILL
2016-11-20 06:53:51,997 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000035
2016-11-20 06:53:51,997 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000035 of capacity <memory:2048, vCores:1> on host cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us:45287, which currently has 10 containers, <memory:20480, vCores:10> used and <memory:12288, vCores:22> available, release resources=true
2016-11-20 06:53:51,997 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000035 on node: host: cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us:45287 #containers=10 available=<memory:12288, vCores:22> used=<memory:20480, vCores:10> with event: KILL
2016-11-20 06:53:51,997 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000068 of event KILL
2016-11-20 06:53:51,997 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000068 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:51,997 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000068 in state: KILLED event:KILL
2016-11-20 06:53:51,997 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000068
2016-11-20 06:53:51,997 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000068 of capacity <memory:2048, vCores:1> on host cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36003, which currently has 11 containers, <memory:22528, vCores:11> used and <memory:10240, vCores:21> available, release resources=true
2016-11-20 06:53:51,997 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000068 on node: host: cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36003 #containers=11 available=<memory:10240, vCores:21> used=<memory:22528, vCores:11> with event: KILL
2016-11-20 06:53:51,997 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000010 of event KILL
2016-11-20 06:53:51,997 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000010 Container Transitioned from RUNNING to KILLED
2016-11-20 06:53:51,997 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000010 in state: KILLED event:KILL
2016-11-20 06:53:51,997 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000010
2016-11-20 06:53:51,997 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000010 of capacity <memory:2048, vCores:1> on host cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38926, which currently has 9 containers, <memory:18432, vCores:9> used and <memory:14336, vCores:23> available, release resources=true
2016-11-20 06:53:51,997 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000010 on node: host: cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38926 #containers=9 available=<memory:14336, vCores:23> used=<memory:18432, vCores:9> with event: KILL
2016-11-20 06:53:51,997 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000039 of event KILL
2016-11-20 06:53:51,997 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000039 Container Transitioned from RUNNING to KILLED
2016-11-20 06:53:51,997 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000039 in state: KILLED event:KILL
2016-11-20 06:53:51,997 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000039
2016-11-20 06:53:51,997 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000039 of capacity <memory:2048, vCores:1> on host cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36804, which currently has 10 containers, <memory:20480, vCores:10> used and <memory:12288, vCores:22> available, release resources=true
2016-11-20 06:53:51,997 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000039 on node: host: cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36804 #containers=10 available=<memory:12288, vCores:22> used=<memory:20480, vCores:10> with event: KILL
2016-11-20 06:53:51,997 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000072 of event KILL
2016-11-20 06:53:51,997 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000072 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:51,997 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000072 in state: KILLED event:KILL
2016-11-20 06:53:51,997 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000072
2016-11-20 06:53:51,997 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000072 of capacity <memory:2048, vCores:1> on host cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us:45287, which currently has 9 containers, <memory:18432, vCores:9> used and <memory:14336, vCores:23> available, release resources=true
2016-11-20 06:53:51,997 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000072 on node: host: cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us:45287 #containers=9 available=<memory:14336, vCores:23> used=<memory:18432, vCores:9> with event: KILL
2016-11-20 06:53:51,997 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000014 of event KILL
2016-11-20 06:53:51,997 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000014 Container Transitioned from RUNNING to KILLED
2016-11-20 06:53:51,997 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000014 in state: KILLED event:KILL
2016-11-20 06:53:51,997 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000014
2016-11-20 06:53:51,997 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000014 of capacity <memory:2048, vCores:1> on host cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us:45287, which currently has 8 containers, <memory:16384, vCores:8> used and <memory:16384, vCores:24> available, release resources=true
2016-11-20 06:53:51,998 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000014 on node: host: cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us:45287 #containers=8 available=<memory:16384, vCores:24> used=<memory:16384, vCores:8> with event: KILL
2016-11-20 06:53:51,998 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000043 of event KILL
2016-11-20 06:53:51,998 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000043 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:51,998 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000043 in state: KILLED event:KILL
2016-11-20 06:53:51,998 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000043
2016-11-20 06:53:51,998 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000043 of capacity <memory:2048, vCores:1> on host cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38926, which currently has 8 containers, <memory:16384, vCores:8> used and <memory:16384, vCores:24> available, release resources=true
2016-11-20 06:53:51,999 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000043 on node: host: cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38926 #containers=8 available=<memory:16384, vCores:24> used=<memory:16384, vCores:8> with event: KILL
2016-11-20 06:53:51,999 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000076 of event KILL
2016-11-20 06:53:51,999 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000076 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:51,999 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000076 in state: KILLED event:KILL
2016-11-20 06:53:51,999 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000076
2016-11-20 06:53:51,999 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000076 of capacity <memory:2048, vCores:1> on host cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38588, which currently has 10 containers, <memory:20480, vCores:10> used and <memory:12288, vCores:22> available, release resources=true
2016-11-20 06:53:51,999 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000076 on node: host: cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38588 #containers=10 available=<memory:12288, vCores:22> used=<memory:20480, vCores:10> with event: KILL
2016-11-20 06:53:51,999 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000018 of event KILL
2016-11-20 06:53:51,999 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000018 Container Transitioned from RUNNING to KILLED
2016-11-20 06:53:51,999 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000018 in state: KILLED event:KILL
2016-11-20 06:53:51,999 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000018
2016-11-20 06:53:51,999 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000018 of capacity <memory:2048, vCores:1> on host cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38926, which currently has 7 containers, <memory:14336, vCores:7> used and <memory:18432, vCores:25> available, release resources=true
2016-11-20 06:53:51,999 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000018 on node: host: cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38926 #containers=7 available=<memory:18432, vCores:25> used=<memory:14336, vCores:7> with event: KILL
2016-11-20 06:53:51,999 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000047 of event KILL
2016-11-20 06:53:52,000 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000047 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,000 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000047 in state: KILLED event:KILL
2016-11-20 06:53:52,000 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000047
2016-11-20 06:53:52,000 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000047 of capacity <memory:2048, vCores:1> on host cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36804, which currently has 9 containers, <memory:18432, vCores:9> used and <memory:14336, vCores:23> available, release resources=true
2016-11-20 06:53:52,000 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000047 on node: host: cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36804 #containers=9 available=<memory:14336, vCores:23> used=<memory:18432, vCores:9> with event: KILL
2016-11-20 06:53:52,000 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000080 of event KILL
2016-11-20 06:53:52,000 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000080 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,000 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000080 in state: KILLED event:KILL
2016-11-20 06:53:52,000 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000080
2016-11-20 06:53:52,000 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000080 of capacity <memory:2048, vCores:1> on host cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36804, which currently has 8 containers, <memory:16384, vCores:8> used and <memory:16384, vCores:24> available, release resources=true
2016-11-20 06:53:52,000 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000080 on node: host: cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36804 #containers=8 available=<memory:16384, vCores:24> used=<memory:16384, vCores:8> with event: KILL
2016-11-20 06:53:52,001 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000022 of event KILL
2016-11-20 06:53:52,001 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000022 Container Transitioned from RUNNING to KILLED
2016-11-20 06:53:52,001 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000022 in state: KILLED event:KILL
2016-11-20 06:53:52,001 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000022
2016-11-20 06:53:52,001 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000022 of capacity <memory:2048, vCores:1> on host cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38588, which currently has 9 containers, <memory:18432, vCores:9> used and <memory:14336, vCores:23> available, release resources=true
2016-11-20 06:53:52,001 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000022 on node: host: cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38588 #containers=9 available=<memory:14336, vCores:23> used=<memory:18432, vCores:9> with event: KILL
2016-11-20 06:53:52,001 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000051 of event KILL
2016-11-20 06:53:52,001 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000051 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,001 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000051 in state: KILLED event:KILL
2016-11-20 06:53:52,001 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000051
2016-11-20 06:53:52,001 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000051 of capacity <memory:2048, vCores:1> on host cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us:45287, which currently has 7 containers, <memory:14336, vCores:7> used and <memory:18432, vCores:25> available, release resources=true
2016-11-20 06:53:52,001 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000051 on node: host: cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us:45287 #containers=7 available=<memory:18432, vCores:25> used=<memory:14336, vCores:7> with event: KILL
2016-11-20 06:53:52,001 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000084 of event KILL
2016-11-20 06:53:52,001 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000084 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,001 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000084 in state: KILLED event:KILL
2016-11-20 06:53:52,001 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000084
2016-11-20 06:53:52,001 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000084 of capacity <memory:2048, vCores:1> on host cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us:33513, which currently has 10 containers, <memory:20480, vCores:10> used and <memory:12288, vCores:22> available, release resources=true
2016-11-20 06:53:52,001 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000084 on node: host: cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us:33513 #containers=10 available=<memory:12288, vCores:22> used=<memory:20480, vCores:10> with event: KILL
2016-11-20 06:53:52,001 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000026 of event KILL
2016-11-20 06:53:52,001 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000026 Container Transitioned from RUNNING to KILLED
2016-11-20 06:53:52,001 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000026 in state: KILLED event:KILL
2016-11-20 06:53:52,001 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000026
2016-11-20 06:53:52,001 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000026 of capacity <memory:2048, vCores:1> on host cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38926, which currently has 6 containers, <memory:12288, vCores:6> used and <memory:20480, vCores:26> available, release resources=true
2016-11-20 06:53:52,002 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000026 on node: host: cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38926 #containers=6 available=<memory:20480, vCores:26> used=<memory:12288, vCores:6> with event: KILL
2016-11-20 06:53:52,002 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000055 of event KILL
2016-11-20 06:53:52,002 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000055 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,002 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000055 in state: KILLED event:KILL
2016-11-20 06:53:52,002 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000055
2016-11-20 06:53:52,002 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000055 of capacity <memory:2048, vCores:1> on host cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38588, which currently has 8 containers, <memory:16384, vCores:8> used and <memory:16384, vCores:24> available, release resources=true
2016-11-20 06:53:52,002 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000055 on node: host: cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38588 #containers=8 available=<memory:16384, vCores:24> used=<memory:16384, vCores:8> with event: KILL
2016-11-20 06:53:52,002 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000088 of event KILL
2016-11-20 06:53:52,002 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000088 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,002 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000088 in state: KILLED event:KILL
2016-11-20 06:53:52,002 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000088
2016-11-20 06:53:52,002 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000088 of capacity <memory:2048, vCores:1> on host cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36003, which currently has 10 containers, <memory:20480, vCores:10> used and <memory:12288, vCores:22> available, release resources=true
2016-11-20 06:53:52,002 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000088 on node: host: cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36003 #containers=10 available=<memory:12288, vCores:22> used=<memory:20480, vCores:10> with event: KILL
2016-11-20 06:53:52,002 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000030 of event KILL
2016-11-20 06:53:52,002 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000030 Container Transitioned from RUNNING to KILLED
2016-11-20 06:53:52,002 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000030 in state: KILLED event:KILL
2016-11-20 06:53:52,002 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000030
2016-11-20 06:53:52,002 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000030 of capacity <memory:2048, vCores:1> on host cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us:46707, which currently has 6 containers, <memory:12288, vCores:6> used and <memory:20480, vCores:26> available, release resources=true
2016-11-20 06:53:52,002 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000030 on node: host: cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us:46707 #containers=6 available=<memory:20480, vCores:26> used=<memory:12288, vCores:6> with event: KILL
2016-11-20 06:53:52,002 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000059 of event KILL
2016-11-20 06:53:52,002 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000059 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,002 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000059 in state: KILLED event:KILL
2016-11-20 06:53:52,002 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000059
2016-11-20 06:53:52,002 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000059 of capacity <memory:2048, vCores:1> on host cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38725, which currently has 11 containers, <memory:22528, vCores:11> used and <memory:10240, vCores:21> available, release resources=true
2016-11-20 06:53:52,002 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000059 on node: host: cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38725 #containers=11 available=<memory:10240, vCores:21> used=<memory:22528, vCores:11> with event: KILL
2016-11-20 06:53:52,002 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000001 of event KILL
2016-11-20 06:53:52,002 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000001 Container Transitioned from RUNNING to KILLED
2016-11-20 06:53:52,002 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000001 in state: KILLED event:KILL
2016-11-20 06:53:52,003 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000001
2016-11-20 06:53:52,003 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000001 of capacity <memory:2048, vCores:1> on host cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us:46707, which currently has 5 containers, <memory:10240, vCores:5> used and <memory:22528, vCores:27> available, release resources=true
2016-11-20 06:53:52,003 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000001 on node: host: cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us:46707 #containers=5 available=<memory:22528, vCores:27> used=<memory:10240, vCores:5> with event: KILL
2016-11-20 06:53:52,003 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000034 of event KILL
2016-11-20 06:53:52,003 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000034 Container Transitioned from RUNNING to KILLED
2016-11-20 06:53:52,003 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000034 in state: KILLED event:KILL
2016-11-20 06:53:52,003 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000034
2016-11-20 06:53:52,003 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000034 of capacity <memory:2048, vCores:1> on host cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38926, which currently has 5 containers, <memory:10240, vCores:5> used and <memory:22528, vCores:27> available, release resources=true
2016-11-20 06:53:52,003 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000034 on node: host: cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38926 #containers=5 available=<memory:22528, vCores:27> used=<memory:10240, vCores:5> with event: KILL
2016-11-20 06:53:52,003 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000063 of event KILL
2016-11-20 06:53:52,003 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000063 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,003 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000063 in state: KILLED event:KILL
2016-11-20 06:53:52,003 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000063
2016-11-20 06:53:52,003 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000063 of capacity <memory:2048, vCores:1> on host cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us:33513, which currently has 9 containers, <memory:18432, vCores:9> used and <memory:14336, vCores:23> available, release resources=true
2016-11-20 06:53:52,003 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000063 on node: host: cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us:33513 #containers=9 available=<memory:14336, vCores:23> used=<memory:18432, vCores:9> with event: KILL
2016-11-20 06:53:52,003 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000005 of event KILL
2016-11-20 06:53:52,003 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000005 Container Transitioned from RUNNING to KILLED
2016-11-20 06:53:52,003 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000005 in state: KILLED event:KILL
2016-11-20 06:53:52,003 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000005
2016-11-20 06:53:52,003 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000005 of capacity <memory:2048, vCores:1> on host cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36804, which currently has 7 containers, <memory:14336, vCores:7> used and <memory:18432, vCores:25> available, release resources=true
2016-11-20 06:53:52,003 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000005 on node: host: cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36804 #containers=7 available=<memory:18432, vCores:25> used=<memory:14336, vCores:7> with event: KILL
2016-11-20 06:53:52,003 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000038 of event KILL
2016-11-20 06:53:52,003 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000038 Container Transitioned from RUNNING to KILLED
2016-11-20 06:53:52,003 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000038 in state: KILLED event:KILL
2016-11-20 06:53:52,004 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000038
2016-11-20 06:53:52,004 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000038 of capacity <memory:2048, vCores:1> on host cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us:46707, which currently has 4 containers, <memory:8192, vCores:4> used and <memory:24576, vCores:28> available, release resources=true
2016-11-20 06:53:52,004 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000038 on node: host: cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us:46707 #containers=4 available=<memory:24576, vCores:28> used=<memory:8192, vCores:4> with event: KILL
2016-11-20 06:53:52,004 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000067 of event KILL
2016-11-20 06:53:52,004 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000067 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,004 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000067 in state: KILLED event:KILL
2016-11-20 06:53:52,004 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000067
2016-11-20 06:53:52,004 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000067 of capacity <memory:2048, vCores:1> on host cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38725, which currently has 10 containers, <memory:20480, vCores:10> used and <memory:12288, vCores:22> available, release resources=true
2016-11-20 06:53:52,004 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000067 on node: host: cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38725 #containers=10 available=<memory:12288, vCores:22> used=<memory:20480, vCores:10> with event: KILL
2016-11-20 06:53:52,004 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000009 of event KILL
2016-11-20 06:53:52,004 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000009 Container Transitioned from RUNNING to KILLED
2016-11-20 06:53:52,004 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000009 in state: KILLED event:KILL
2016-11-20 06:53:52,004 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000009
2016-11-20 06:53:52,004 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000009 of capacity <memory:2048, vCores:1> on host cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us:46707, which currently has 3 containers, <memory:6144, vCores:3> used and <memory:26624, vCores:29> available, release resources=true
2016-11-20 06:53:52,004 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000009 on node: host: cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us:46707 #containers=3 available=<memory:26624, vCores:29> used=<memory:6144, vCores:3> with event: KILL
2016-11-20 06:53:52,004 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000042 of event KILL
2016-11-20 06:53:52,004 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000042 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,004 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000042 in state: KILLED event:KILL
2016-11-20 06:53:52,004 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000042
2016-11-20 06:53:52,004 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000042 of capacity <memory:2048, vCores:1> on host cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us:46707, which currently has 2 containers, <memory:4096, vCores:2> used and <memory:28672, vCores:30> available, release resources=true
2016-11-20 06:53:52,004 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000042 on node: host: cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us:46707 #containers=2 available=<memory:28672, vCores:30> used=<memory:4096, vCores:2> with event: KILL
2016-11-20 06:53:52,004 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000071 of event KILL
2016-11-20 06:53:52,004 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000071 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,005 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000071 in state: KILLED event:KILL
2016-11-20 06:53:52,005 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000071
2016-11-20 06:53:52,005 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000071 of capacity <memory:2048, vCores:1> on host cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38926, which currently has 4 containers, <memory:8192, vCores:4> used and <memory:24576, vCores:28> available, release resources=true
2016-11-20 06:53:52,005 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000071 on node: host: cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38926 #containers=4 available=<memory:24576, vCores:28> used=<memory:8192, vCores:4> with event: KILL
2016-11-20 06:53:52,005 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000013 of event KILL
2016-11-20 06:53:52,005 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000013 Container Transitioned from RUNNING to KILLED
2016-11-20 06:53:52,005 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000013 in state: KILLED event:KILL
2016-11-20 06:53:52,005 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000013
2016-11-20 06:53:52,005 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000013 of capacity <memory:2048, vCores:1> on host cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36003, which currently has 9 containers, <memory:18432, vCores:9> used and <memory:14336, vCores:23> available, release resources=true
2016-11-20 06:53:52,005 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000013 on node: host: cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36003 #containers=9 available=<memory:14336, vCores:23> used=<memory:18432, vCores:9> with event: KILL
2016-11-20 06:53:52,005 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000046 of event KILL
2016-11-20 06:53:52,005 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000046 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,005 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000046 in state: KILLED event:KILL
2016-11-20 06:53:52,005 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000046
2016-11-20 06:53:52,005 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000046 of capacity <memory:2048, vCores:1> on host cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38725, which currently has 9 containers, <memory:18432, vCores:9> used and <memory:14336, vCores:23> available, release resources=true
2016-11-20 06:53:52,005 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000046 on node: host: cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38725 #containers=9 available=<memory:14336, vCores:23> used=<memory:18432, vCores:9> with event: KILL
2016-11-20 06:53:52,005 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000075 of event KILL
2016-11-20 06:53:52,005 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000075 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,005 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000075 in state: KILLED event:KILL
2016-11-20 06:53:52,006 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000075
2016-11-20 06:53:52,006 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000075 of capacity <memory:2048, vCores:1> on host cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38725, which currently has 8 containers, <memory:16384, vCores:8> used and <memory:16384, vCores:24> available, release resources=true
2016-11-20 06:53:52,006 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000075 on node: host: cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38725 #containers=8 available=<memory:16384, vCores:24> used=<memory:16384, vCores:8> with event: KILL
2016-11-20 06:53:52,006 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000017 of event KILL
2016-11-20 06:53:52,006 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000017 Container Transitioned from RUNNING to KILLED
2016-11-20 06:53:52,006 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000017 in state: KILLED event:KILL
2016-11-20 06:53:52,006 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000017
2016-11-20 06:53:52,006 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000017 of capacity <memory:2048, vCores:1> on host cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us:46707, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:30720, vCores:31> available, release resources=true
2016-11-20 06:53:52,006 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000017 on node: host: cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us:46707 #containers=1 available=<memory:30720, vCores:31> used=<memory:2048, vCores:1> with event: KILL
2016-11-20 06:53:52,006 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000050 of event KILL
2016-11-20 06:53:52,006 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000050 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,006 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000050 in state: KILLED event:KILL
2016-11-20 06:53:52,006 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000050
2016-11-20 06:53:52,006 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000050 of capacity <memory:2048, vCores:1> on host cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38926, which currently has 3 containers, <memory:6144, vCores:3> used and <memory:26624, vCores:29> available, release resources=true
2016-11-20 06:53:52,006 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000050 on node: host: cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38926 #containers=3 available=<memory:26624, vCores:29> used=<memory:6144, vCores:3> with event: KILL
2016-11-20 06:53:52,006 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000079 of event KILL
2016-11-20 06:53:52,006 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000079 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,006 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000079 in state: KILLED event:KILL
2016-11-20 06:53:52,006 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000079
2016-11-20 06:53:52,006 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000079 of capacity <memory:2048, vCores:1> on host cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us:45287, which currently has 6 containers, <memory:12288, vCores:6> used and <memory:20480, vCores:26> available, release resources=true
2016-11-20 06:53:52,006 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000079 on node: host: cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us:45287 #containers=6 available=<memory:20480, vCores:26> used=<memory:12288, vCores:6> with event: KILL
2016-11-20 06:53:52,008 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000021 of event KILL
2016-11-20 06:53:52,008 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000021 Container Transitioned from RUNNING to KILLED
2016-11-20 06:53:52,008 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000021 in state: KILLED event:KILL
2016-11-20 06:53:52,008 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000021
2016-11-20 06:53:52,008 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000021 of capacity <memory:2048, vCores:1> on host cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36003, which currently has 8 containers, <memory:16384, vCores:8> used and <memory:16384, vCores:24> available, release resources=true
2016-11-20 06:53:52,008 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000021 on node: host: cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36003 #containers=8 available=<memory:16384, vCores:24> used=<memory:16384, vCores:8> with event: KILL
2016-11-20 06:53:52,008 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000054 of event KILL
2016-11-20 06:53:52,008 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000054 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,008 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000054 in state: KILLED event:KILL
2016-11-20 06:53:52,008 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000054
2016-11-20 06:53:52,008 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000054 of capacity <memory:2048, vCores:1> on host cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36804, which currently has 6 containers, <memory:12288, vCores:6> used and <memory:20480, vCores:26> available, release resources=true
2016-11-20 06:53:52,008 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000054 on node: host: cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36804 #containers=6 available=<memory:20480, vCores:26> used=<memory:12288, vCores:6> with event: KILL
2016-11-20 06:53:52,008 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000083 of event KILL
2016-11-20 06:53:52,008 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000083 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,008 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000083 in state: KILLED event:KILL
2016-11-20 06:53:52,008 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000083
2016-11-20 06:53:52,008 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000083 of capacity <memory:2048, vCores:1> on host cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38588, which currently has 7 containers, <memory:14336, vCores:7> used and <memory:18432, vCores:25> available, release resources=true
2016-11-20 06:53:52,008 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000083 on node: host: cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38588 #containers=7 available=<memory:18432, vCores:25> used=<memory:14336, vCores:7> with event: KILL
2016-11-20 06:53:52,008 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000025 of event KILL
2016-11-20 06:53:52,008 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000025 Container Transitioned from RUNNING to KILLED
2016-11-20 06:53:52,009 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000025 in state: KILLED event:KILL
2016-11-20 06:53:52,009 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000025
2016-11-20 06:53:52,009 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000025 of capacity <memory:2048, vCores:1> on host cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36804, which currently has 5 containers, <memory:10240, vCores:5> used and <memory:22528, vCores:27> available, release resources=true
2016-11-20 06:53:52,009 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000025 on node: host: cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36804 #containers=5 available=<memory:22528, vCores:27> used=<memory:10240, vCores:5> with event: KILL
2016-11-20 06:53:52,009 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000058 of event KILL
2016-11-20 06:53:52,009 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000058 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,009 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000058 in state: KILLED event:KILL
2016-11-20 06:53:52,009 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000058
2016-11-20 06:53:52,009 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000058 of capacity <memory:2048, vCores:1> on host cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us:45287, which currently has 5 containers, <memory:10240, vCores:5> used and <memory:22528, vCores:27> available, release resources=true
2016-11-20 06:53:52,009 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000058 on node: host: cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us:45287 #containers=5 available=<memory:22528, vCores:27> used=<memory:10240, vCores:5> with event: KILL
2016-11-20 06:53:52,009 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000087 of event KILL
2016-11-20 06:53:52,009 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000087 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,009 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000087 in state: KILLED event:KILL
2016-11-20 06:53:52,009 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000087
2016-11-20 06:53:52,009 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000087 of capacity <memory:2048, vCores:1> on host cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36804, which currently has 4 containers, <memory:8192, vCores:4> used and <memory:24576, vCores:28> available, release resources=true
2016-11-20 06:53:52,009 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000087 on node: host: cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36804 #containers=4 available=<memory:24576, vCores:28> used=<memory:8192, vCores:4> with event: KILL
2016-11-20 06:53:52,009 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000029 of event KILL
2016-11-20 06:53:52,009 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000029 Container Transitioned from RUNNING to KILLED
2016-11-20 06:53:52,009 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000029 in state: KILLED event:KILL
2016-11-20 06:53:52,009 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000029
2016-11-20 06:53:52,009 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000029 of capacity <memory:2048, vCores:1> on host cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36003, which currently has 7 containers, <memory:14336, vCores:7> used and <memory:18432, vCores:25> available, release resources=true
2016-11-20 06:53:52,009 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000029 on node: host: cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36003 #containers=7 available=<memory:18432, vCores:25> used=<memory:14336, vCores:7> with event: KILL
2016-11-20 06:53:52,009 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000062 of event KILL
2016-11-20 06:53:52,009 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000062 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,009 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000062 in state: KILLED event:KILL
2016-11-20 06:53:52,009 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000062
2016-11-20 06:53:52,009 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000062 of capacity <memory:2048, vCores:1> on host cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38588, which currently has 6 containers, <memory:12288, vCores:6> used and <memory:20480, vCores:26> available, release resources=true
2016-11-20 06:53:52,009 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000062 on node: host: cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38588 #containers=6 available=<memory:20480, vCores:26> used=<memory:12288, vCores:6> with event: KILL
2016-11-20 06:53:52,009 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000033 of event KILL
2016-11-20 06:53:52,009 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000033 Container Transitioned from RUNNING to KILLED
2016-11-20 06:53:52,009 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000033 in state: KILLED event:KILL
2016-11-20 06:53:52,009 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000033
2016-11-20 06:53:52,009 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000033 of capacity <memory:2048, vCores:1> on host cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38588, which currently has 5 containers, <memory:10240, vCores:5> used and <memory:22528, vCores:27> available, release resources=true
2016-11-20 06:53:52,009 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000033 on node: host: cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38588 #containers=5 available=<memory:22528, vCores:27> used=<memory:10240, vCores:5> with event: KILL
2016-11-20 06:53:52,009 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000066 of event KILL
2016-11-20 06:53:52,009 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000066 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,009 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000066 in state: KILLED event:KILL
2016-11-20 06:53:52,009 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000066
2016-11-20 06:53:52,010 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000066 of capacity <memory:2048, vCores:1> on host cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36804, which currently has 3 containers, <memory:6144, vCores:3> used and <memory:26624, vCores:29> available, release resources=true
2016-11-20 06:53:52,010 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000066 on node: host: cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36804 #containers=3 available=<memory:26624, vCores:29> used=<memory:6144, vCores:3> with event: KILL
2016-11-20 06:53:52,010 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000037 of event KILL
2016-11-20 06:53:52,010 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000037 Container Transitioned from RUNNING to KILLED
2016-11-20 06:53:52,010 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000037 in state: KILLED event:KILL
2016-11-20 06:53:52,010 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000037
2016-11-20 06:53:52,010 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000037 of capacity <memory:2048, vCores:1> on host cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36003, which currently has 6 containers, <memory:12288, vCores:6> used and <memory:20480, vCores:26> available, release resources=true
2016-11-20 06:53:52,010 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000037 on node: host: cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36003 #containers=6 available=<memory:20480, vCores:26> used=<memory:12288, vCores:6> with event: KILL
2016-11-20 06:53:52,010 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000070 of event KILL
2016-11-20 06:53:52,010 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000070 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,010 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000070 in state: KILLED event:KILL
2016-11-20 06:53:52,010 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000070
2016-11-20 06:53:52,010 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000070 of capacity <memory:2048, vCores:1> on host cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us:33513, which currently has 8 containers, <memory:16384, vCores:8> used and <memory:16384, vCores:24> available, release resources=true
2016-11-20 06:53:52,010 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000070 on node: host: cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us:33513 #containers=8 available=<memory:16384, vCores:24> used=<memory:16384, vCores:8> with event: KILL
2016-11-20 06:53:52,010 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000004 of event KILL
2016-11-20 06:53:52,010 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000004 Container Transitioned from RUNNING to KILLED
2016-11-20 06:53:52,010 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000004 in state: KILLED event:KILL
2016-11-20 06:53:52,010 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000004
2016-11-20 06:53:52,010 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000004 of capacity <memory:2048, vCores:1> on host cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36003, which currently has 5 containers, <memory:10240, vCores:5> used and <memory:22528, vCores:27> available, release resources=true
2016-11-20 06:53:52,010 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000004 on node: host: cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36003 #containers=5 available=<memory:22528, vCores:27> used=<memory:10240, vCores:5> with event: KILL
2016-11-20 06:53:52,010 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000041 of event KILL
2016-11-20 06:53:52,010 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000041 Container Transitioned from RUNNING to KILLED
2016-11-20 06:53:52,010 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000041 in state: KILLED event:KILL
2016-11-20 06:53:52,010 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000041
2016-11-20 06:53:52,010 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000041 of capacity <memory:2048, vCores:1> on host cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38588, which currently has 4 containers, <memory:8192, vCores:4> used and <memory:24576, vCores:28> available, release resources=true
2016-11-20 06:53:52,010 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000041 on node: host: cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38588 #containers=4 available=<memory:24576, vCores:28> used=<memory:8192, vCores:4> with event: KILL
2016-11-20 06:53:52,010 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000074 of event KILL
2016-11-20 06:53:52,010 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000074 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,010 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000074 in state: KILLED event:KILL
2016-11-20 06:53:52,010 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000074
2016-11-20 06:53:52,010 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000074 of capacity <memory:2048, vCores:1> on host cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36003, which currently has 4 containers, <memory:8192, vCores:4> used and <memory:24576, vCores:28> available, release resources=true
2016-11-20 06:53:52,010 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000074 on node: host: cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36003 #containers=4 available=<memory:24576, vCores:28> used=<memory:8192, vCores:4> with event: KILL
2016-11-20 06:53:52,010 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000008 of event KILL
2016-11-20 06:53:52,010 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000008 Container Transitioned from RUNNING to KILLED
2016-11-20 06:53:52,010 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000008 in state: KILLED event:KILL
2016-11-20 06:53:52,010 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000008
2016-11-20 06:53:52,010 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000008 of capacity <memory:2048, vCores:1> on host cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us:33513, which currently has 7 containers, <memory:14336, vCores:7> used and <memory:18432, vCores:25> available, release resources=true
2016-11-20 06:53:52,010 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000008 on node: host: cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us:33513 #containers=7 available=<memory:18432, vCores:25> used=<memory:14336, vCores:7> with event: KILL
2016-11-20 06:53:52,010 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000045 of event KILL
2016-11-20 06:53:52,011 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000045 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,011 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000045 in state: KILLED event:KILL
2016-11-20 06:53:52,011 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000045
2016-11-20 06:53:52,011 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000045 of capacity <memory:2048, vCores:1> on host cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36003, which currently has 3 containers, <memory:6144, vCores:3> used and <memory:26624, vCores:29> available, release resources=true
2016-11-20 06:53:52,011 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000045 on node: host: cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36003 #containers=3 available=<memory:26624, vCores:29> used=<memory:6144, vCores:3> with event: KILL
2016-11-20 06:53:52,011 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000078 of event KILL
2016-11-20 06:53:52,011 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000078 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,011 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000078 in state: KILLED event:KILL
2016-11-20 06:53:52,011 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000078
2016-11-20 06:53:52,011 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000078 of capacity <memory:2048, vCores:1> on host cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38926, which currently has 2 containers, <memory:4096, vCores:2> used and <memory:28672, vCores:30> available, release resources=true
2016-11-20 06:53:52,011 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000078 on node: host: cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38926 #containers=2 available=<memory:28672, vCores:30> used=<memory:4096, vCores:2> with event: KILL
2016-11-20 06:53:52,011 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000012 of event KILL
2016-11-20 06:53:52,011 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000012 Container Transitioned from RUNNING to KILLED
2016-11-20 06:53:52,011 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000012 in state: KILLED event:KILL
2016-11-20 06:53:52,011 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000012
2016-11-20 06:53:52,011 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000012 of capacity <memory:2048, vCores:1> on host cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36804, which currently has 2 containers, <memory:4096, vCores:2> used and <memory:28672, vCores:30> available, release resources=true
2016-11-20 06:53:52,011 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000012 on node: host: cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36804 #containers=2 available=<memory:28672, vCores:30> used=<memory:4096, vCores:2> with event: KILL
2016-11-20 06:53:52,011 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000049 of event KILL
2016-11-20 06:53:52,011 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000049 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,011 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000049 in state: KILLED event:KILL
2016-11-20 06:53:52,011 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000049
2016-11-20 06:53:52,011 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000049 of capacity <memory:2048, vCores:1> on host cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us:33513, which currently has 6 containers, <memory:12288, vCores:6> used and <memory:20480, vCores:26> available, release resources=true
2016-11-20 06:53:52,011 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000049 on node: host: cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us:33513 #containers=6 available=<memory:20480, vCores:26> used=<memory:12288, vCores:6> with event: KILL
2016-11-20 06:53:52,011 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000082 of event KILL
2016-11-20 06:53:52,011 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000082 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,011 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000082 in state: KILLED event:KILL
2016-11-20 06:53:52,011 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000082
2016-11-20 06:53:52,011 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000082 of capacity <memory:2048, vCores:1> on host cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38725, which currently has 7 containers, <memory:14336, vCores:7> used and <memory:18432, vCores:25> available, release resources=true
2016-11-20 06:53:52,011 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000082 on node: host: cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38725 #containers=7 available=<memory:18432, vCores:25> used=<memory:14336, vCores:7> with event: KILL
2016-11-20 06:53:52,011 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000016 of event KILL
2016-11-20 06:53:52,011 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000016 Container Transitioned from RUNNING to KILLED
2016-11-20 06:53:52,011 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000016 in state: KILLED event:KILL
2016-11-20 06:53:52,011 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000016
2016-11-20 06:53:52,011 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000016 of capacity <memory:2048, vCores:1> on host cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us:33513, which currently has 5 containers, <memory:10240, vCores:5> used and <memory:22528, vCores:27> available, release resources=true
2016-11-20 06:53:52,011 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000016 on node: host: cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us:33513 #containers=5 available=<memory:22528, vCores:27> used=<memory:10240, vCores:5> with event: KILL
2016-11-20 06:53:52,011 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000053 of event KILL
2016-11-20 06:53:52,012 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000053 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,012 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000053 in state: KILLED event:KILL
2016-11-20 06:53:52,012 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000053
2016-11-20 06:53:52,012 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000053 of capacity <memory:2048, vCores:1> on host cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38725, which currently has 6 containers, <memory:12288, vCores:6> used and <memory:20480, vCores:26> available, release resources=true
2016-11-20 06:53:52,012 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000053 on node: host: cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38725 #containers=6 available=<memory:20480, vCores:26> used=<memory:12288, vCores:6> with event: KILL
2016-11-20 06:53:52,012 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000086 of event KILL
2016-11-20 06:53:52,012 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000086 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,012 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000086 in state: KILLED event:KILL
2016-11-20 06:53:52,012 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000086
2016-11-20 06:53:52,012 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000086 of capacity <memory:2048, vCores:1> on host cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38926, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:30720, vCores:31> available, release resources=true
2016-11-20 06:53:52,012 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000086 on node: host: cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38926 #containers=1 available=<memory:30720, vCores:31> used=<memory:2048, vCores:1> with event: KILL
2016-11-20 06:53:52,012 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000020 of event KILL
2016-11-20 06:53:52,012 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000020 Container Transitioned from RUNNING to KILLED
2016-11-20 06:53:52,012 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000020 in state: KILLED event:KILL
2016-11-20 06:53:52,012 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000020
2016-11-20 06:53:52,012 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000020 of capacity <memory:2048, vCores:1> on host cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us:45287, which currently has 4 containers, <memory:8192, vCores:4> used and <memory:24576, vCores:28> available, release resources=true
2016-11-20 06:53:52,012 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000020 on node: host: cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us:45287 #containers=4 available=<memory:24576, vCores:28> used=<memory:8192, vCores:4> with event: KILL
2016-11-20 06:53:52,012 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000057 of event KILL
2016-11-20 06:53:52,012 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000057 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,012 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000057 in state: KILLED event:KILL
2016-11-20 06:53:52,012 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000057
2016-11-20 06:53:52,012 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000057 of capacity <memory:2048, vCores:1> on host cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38926, which currently has 0 containers, <memory:0, vCores:0> used and <memory:32768, vCores:32> available, release resources=true
2016-11-20 06:53:52,012 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000057 on node: host: cp-8.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38926 #containers=0 available=<memory:32768, vCores:32> used=<memory:0, vCores:0> with event: KILL
2016-11-20 06:53:52,012 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000024 of event KILL
2016-11-20 06:53:52,012 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000024 Container Transitioned from RUNNING to KILLED
2016-11-20 06:53:52,012 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000024 in state: KILLED event:KILL
2016-11-20 06:53:52,012 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000024
2016-11-20 06:53:52,012 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000024 of capacity <memory:2048, vCores:1> on host cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us:33513, which currently has 4 containers, <memory:8192, vCores:4> used and <memory:24576, vCores:28> available, release resources=true
2016-11-20 06:53:52,012 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000024 on node: host: cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us:33513 #containers=4 available=<memory:24576, vCores:28> used=<memory:8192, vCores:4> with event: KILL
2016-11-20 06:53:52,012 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000061 of event KILL
2016-11-20 06:53:52,012 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000061 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,012 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000061 in state: KILLED event:KILL
2016-11-20 06:53:52,012 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000061
2016-11-20 06:53:52,012 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000061 of capacity <memory:2048, vCores:1> on host cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36804, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:30720, vCores:31> available, release resources=true
2016-11-20 06:53:52,012 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000061 on node: host: cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36804 #containers=1 available=<memory:30720, vCores:31> used=<memory:2048, vCores:1> with event: KILL
2016-11-20 06:53:52,012 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000028 of event KILL
2016-11-20 06:53:52,012 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000028 Container Transitioned from RUNNING to KILLED
2016-11-20 06:53:52,012 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000028 in state: KILLED event:KILL
2016-11-20 06:53:52,012 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000028
2016-11-20 06:53:52,013 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000028 of capacity <memory:2048, vCores:1> on host cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us:45287, which currently has 3 containers, <memory:6144, vCores:3> used and <memory:26624, vCores:29> available, release resources=true
2016-11-20 06:53:52,013 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000028 on node: host: cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us:45287 #containers=3 available=<memory:26624, vCores:29> used=<memory:6144, vCores:3> with event: KILL
2016-11-20 06:53:52,013 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000065 of event KILL
2016-11-20 06:53:52,013 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000065 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,013 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000065 in state: KILLED event:KILL
2016-11-20 06:53:52,013 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000065
2016-11-20 06:53:52,013 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000065 of capacity <memory:2048, vCores:1> on host cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us:45287, which currently has 2 containers, <memory:4096, vCores:2> used and <memory:28672, vCores:30> available, release resources=true
2016-11-20 06:53:52,013 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000065 on node: host: cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us:45287 #containers=2 available=<memory:28672, vCores:30> used=<memory:4096, vCores:2> with event: KILL
2016-11-20 06:53:52,013 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000032 of event KILL
2016-11-20 06:53:52,013 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000032 Container Transitioned from RUNNING to KILLED
2016-11-20 06:53:52,013 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000032 in state: KILLED event:KILL
2016-11-20 06:53:52,013 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000032
2016-11-20 06:53:52,013 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000032 of capacity <memory:2048, vCores:1> on host cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us:33513, which currently has 3 containers, <memory:6144, vCores:3> used and <memory:26624, vCores:29> available, release resources=true
2016-11-20 06:53:52,013 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000032 on node: host: cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us:33513 #containers=3 available=<memory:26624, vCores:29> used=<memory:6144, vCores:3> with event: KILL
2016-11-20 06:53:52,013 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000069 of event KILL
2016-11-20 06:53:52,013 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000069 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,013 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000069 in state: KILLED event:KILL
2016-11-20 06:53:52,013 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000069
2016-11-20 06:53:52,013 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000069 of capacity <memory:2048, vCores:1> on host cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38588, which currently has 3 containers, <memory:6144, vCores:3> used and <memory:26624, vCores:29> available, release resources=true
2016-11-20 06:53:52,013 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000069 on node: host: cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38588 #containers=3 available=<memory:26624, vCores:29> used=<memory:6144, vCores:3> with event: KILL
2016-11-20 06:53:52,013 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000003 of event KILL
2016-11-20 06:53:52,013 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000003 Container Transitioned from RUNNING to KILLED
2016-11-20 06:53:52,013 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000003 in state: KILLED event:KILL
2016-11-20 06:53:52,014 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000003
2016-11-20 06:53:52,014 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000003 of capacity <memory:2048, vCores:1> on host cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38588, which currently has 2 containers, <memory:4096, vCores:2> used and <memory:28672, vCores:30> available, release resources=true
2016-11-20 06:53:52,014 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000003 on node: host: cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38588 #containers=2 available=<memory:28672, vCores:30> used=<memory:4096, vCores:2> with event: KILL
2016-11-20 06:53:52,014 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000036 of event KILL
2016-11-20 06:53:52,014 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000036 Container Transitioned from RUNNING to KILLED
2016-11-20 06:53:52,014 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000036 in state: KILLED event:KILL
2016-11-20 06:53:52,014 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000036
2016-11-20 06:53:52,014 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000036 of capacity <memory:2048, vCores:1> on host cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38725, which currently has 5 containers, <memory:10240, vCores:5> used and <memory:22528, vCores:27> available, release resources=true
2016-11-20 06:53:52,014 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000036 on node: host: cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38725 #containers=5 available=<memory:22528, vCores:27> used=<memory:10240, vCores:5> with event: KILL
2016-11-20 06:53:52,014 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000073 of event KILL
2016-11-20 06:53:52,014 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000073 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,014 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000073 in state: KILLED event:KILL
2016-11-20 06:53:52,014 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000073
2016-11-20 06:53:52,014 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000073 of capacity <memory:2048, vCores:1> on host cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36804, which currently has 0 containers, <memory:0, vCores:0> used and <memory:32768, vCores:32> available, release resources=true
2016-11-20 06:53:52,014 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000073 on node: host: cp-3.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36804 #containers=0 available=<memory:32768, vCores:32> used=<memory:0, vCores:0> with event: KILL
2016-11-20 06:53:52,014 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000007 of event KILL
2016-11-20 06:53:52,014 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000007 Container Transitioned from RUNNING to KILLED
2016-11-20 06:53:52,014 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000007 in state: KILLED event:KILL
2016-11-20 06:53:52,014 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000007
2016-11-20 06:53:52,014 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000007 of capacity <memory:2048, vCores:1> on host cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38725, which currently has 4 containers, <memory:8192, vCores:4> used and <memory:24576, vCores:28> available, release resources=true
2016-11-20 06:53:52,014 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000007 on node: host: cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38725 #containers=4 available=<memory:24576, vCores:28> used=<memory:8192, vCores:4> with event: KILL
2016-11-20 06:53:52,014 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000040 of event KILL
2016-11-20 06:53:52,014 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000040 Container Transitioned from RUNNING to KILLED
2016-11-20 06:53:52,014 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000040 in state: KILLED event:KILL
2016-11-20 06:53:52,014 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000040
2016-11-20 06:53:52,014 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000040 of capacity <memory:2048, vCores:1> on host cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us:33513, which currently has 2 containers, <memory:4096, vCores:2> used and <memory:28672, vCores:30> available, release resources=true
2016-11-20 06:53:52,014 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000040 on node: host: cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us:33513 #containers=2 available=<memory:28672, vCores:30> used=<memory:4096, vCores:2> with event: KILL
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000077 of event KILL
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000077 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000077 in state: KILLED event:KILL
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000077
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000077 of capacity <memory:2048, vCores:1> on host cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us:33513, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:30720, vCores:31> available, release resources=true
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000077 on node: host: cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us:33513 #containers=1 available=<memory:30720, vCores:31> used=<memory:2048, vCores:1> with event: KILL
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000011 of event KILL
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000011 Container Transitioned from RUNNING to KILLED
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000011 in state: KILLED event:KILL
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000011
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000011 of capacity <memory:2048, vCores:1> on host cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38588, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:30720, vCores:31> available, release resources=true
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000011 on node: host: cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38588 #containers=1 available=<memory:30720, vCores:31> used=<memory:2048, vCores:1> with event: KILL
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000044 of event KILL
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000044 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000044 in state: KILLED event:KILL
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000044
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000044 of capacity <memory:2048, vCores:1> on host cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us:45287, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:30720, vCores:31> available, release resources=true
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000044 on node: host: cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us:45287 #containers=1 available=<memory:30720, vCores:31> used=<memory:2048, vCores:1> with event: KILL
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000081 of event KILL
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000081 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000081 in state: KILLED event:KILL
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000081
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000081 of capacity <memory:2048, vCores:1> on host cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36003, which currently has 2 containers, <memory:4096, vCores:2> used and <memory:28672, vCores:30> available, release resources=true
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000081 on node: host: cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36003 #containers=2 available=<memory:28672, vCores:30> used=<memory:4096, vCores:2> with event: KILL
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000015 of event KILL
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000015 Container Transitioned from RUNNING to KILLED
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000015 in state: KILLED event:KILL
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000015
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000015 of capacity <memory:2048, vCores:1> on host cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38725, which currently has 3 containers, <memory:6144, vCores:3> used and <memory:26624, vCores:29> available, release resources=true
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000015 on node: host: cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38725 #containers=3 available=<memory:26624, vCores:29> used=<memory:6144, vCores:3> with event: KILL
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000048 of event KILL
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000048 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000048 in state: KILLED event:KILL
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000048
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000048 of capacity <memory:2048, vCores:1> on host cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38588, which currently has 0 containers, <memory:0, vCores:0> used and <memory:32768, vCores:32> available, release resources=true
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000048 on node: host: cp-2.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38588 #containers=0 available=<memory:32768, vCores:32> used=<memory:0, vCores:0> with event: KILL
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000085 of event KILL
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000085 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000085 in state: KILLED event:KILL
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000085
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000085 of capacity <memory:2048, vCores:1> on host cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us:45287, which currently has 0 containers, <memory:0, vCores:0> used and <memory:32768, vCores:32> available, release resources=true
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000085 on node: host: cp-4.yarn-perf.yarnrm-PG0.utah.cloudlab.us:45287 #containers=0 available=<memory:32768, vCores:32> used=<memory:0, vCores:0> with event: KILL
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000019 of event KILL
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000019 Container Transitioned from RUNNING to KILLED
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000019 in state: KILLED event:KILL
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000019
2016-11-20 06:53:52,015 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000019 of capacity <memory:2048, vCores:1> on host cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38725, which currently has 2 containers, <memory:4096, vCores:2> used and <memory:28672, vCores:30> available, release resources=true
2016-11-20 06:53:52,016 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000019 on node: host: cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38725 #containers=2 available=<memory:28672, vCores:30> used=<memory:4096, vCores:2> with event: KILL
2016-11-20 06:53:52,016 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000052 of event KILL
2016-11-20 06:53:52,016 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000052 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,016 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000052 in state: KILLED event:KILL
2016-11-20 06:53:52,016 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000052
2016-11-20 06:53:52,016 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000052 of capacity <memory:2048, vCores:1> on host cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36003, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:30720, vCores:31> available, release resources=true
2016-11-20 06:53:52,016 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000052 on node: host: cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36003 #containers=1 available=<memory:30720, vCores:31> used=<memory:2048, vCores:1> with event: KILL
2016-11-20 06:53:52,016 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000089 of event KILL
2016-11-20 06:53:52,016 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000089 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,016 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000089 in state: KILLED event:KILL
2016-11-20 06:53:52,016 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000089
2016-11-20 06:53:52,016 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000089 of capacity <memory:2048, vCores:1> on host cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38725, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:30720, vCores:31> available, release resources=true
2016-11-20 06:53:52,016 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000089 on node: host: cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38725 #containers=1 available=<memory:30720, vCores:31> used=<memory:2048, vCores:1> with event: KILL
2016-11-20 06:53:52,016 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000023 of event KILL
2016-11-20 06:53:52,016 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000023 Container Transitioned from RUNNING to KILLED
2016-11-20 06:53:52,016 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000023 in state: KILLED event:KILL
2016-11-20 06:53:52,016 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000023
2016-11-20 06:53:52,016 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000023 of capacity <memory:2048, vCores:1> on host cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us:46707, which currently has 0 containers, <memory:0, vCores:0> used and <memory:32768, vCores:32> available, release resources=true
2016-11-20 06:53:52,016 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000023 on node: host: cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us:46707 #containers=0 available=<memory:32768, vCores:32> used=<memory:0, vCores:0> with event: KILL
2016-11-20 06:53:52,016 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000056 of event KILL
2016-11-20 06:53:52,016 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000056 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,016 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000056 in state: KILLED event:KILL
2016-11-20 06:53:52,016 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000056
2016-11-20 06:53:52,016 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000056 of capacity <memory:2048, vCores:1> on host cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us:33513, which currently has 0 containers, <memory:0, vCores:0> used and <memory:32768, vCores:32> available, release resources=true
2016-11-20 06:53:52,016 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000056 on node: host: cp-7.yarn-perf.yarnrm-PG0.utah.cloudlab.us:33513 #containers=0 available=<memory:32768, vCores:32> used=<memory:0, vCores:0> with event: KILL
2016-11-20 06:53:52,016 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000027 of event KILL
2016-11-20 06:53:52,016 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000027 Container Transitioned from RUNNING to KILLED
2016-11-20 06:53:52,016 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000027 in state: KILLED event:KILL
2016-11-20 06:53:52,016 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000027
2016-11-20 06:53:52,016 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000027 of capacity <memory:2048, vCores:1> on host cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38725, which currently has 0 containers, <memory:0, vCores:0> used and <memory:32768, vCores:32> available, release resources=true
2016-11-20 06:53:52,016 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000027 on node: host: cp-6.yarn-perf.yarnrm-PG0.utah.cloudlab.us:38725 #containers=0 available=<memory:32768, vCores:32> used=<memory:0, vCores:0> with event: KILL
2016-11-20 06:53:52,016 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: Processing container_1479632525694_0001_01_000060 of event KILL
2016-11-20 06:53:52,016 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1479632525694_0001_01_000060 Container Transitioned from ALLOCATED to KILLED
2016-11-20 06:53:52,016 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt: Completed container: container_1479632525694_0001_01_000060 in state: KILLED event:KILL
2016-11-20 06:53:52,016 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1479632525694_0001	CONTAINERID=container_1479632525694_0001_01_000060
2016-11-20 06:53:52,016 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1479632525694_0001_01_000060 of capacity <memory:2048, vCores:1> on host cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36003, which currently has 0 containers, <memory:0, vCores:0> used and <memory:32768, vCores:32> available, release resources=true
2016-11-20 06:53:52,016 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1479632525694_0001_000001 released container container_1479632525694_0001_01_000060 on node: host: cp-1.yarn-perf.yarnrm-PG0.utah.cloudlab.us:36003 #containers=0 available=<memory:32768, vCores:32> used=<memory:0, vCores:0> with event: KILL
2016-11-20 06:53:52,016 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1479632525694_0001 requests cleared
2016-11-20 06:53:52,016 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue: queue: root.bursty0 include 0 active apps: []
2016-11-20 06:53:52,017 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: set queue: [root.bursty0, demand=<memory:182272, vCores:89>, running=<memory:0, vCores:0>, share=<memory:262144, vCores:256>, w=<memory weight=1.0, cpu weight=1.0>] isRunning=false if there are no runnable apps
2016-11-20 06:53:52,192 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=tanle	IP=128.110.153.236	OPERATION=Kill Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1479632525694_0001
2016-11-20 06:53:52,999 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us/128.110.153.239:46707. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-11-20 06:53:54,000 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us/128.110.153.239:46707. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-11-20 06:53:55,002 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us/128.110.153.239:46707. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-11-20 06:53:56,003 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us/128.110.153.239:46707. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-11-20 06:53:57,004 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us/128.110.153.239:46707. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-11-20 06:53:58,005 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us/128.110.153.239:46707. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-11-20 06:53:59,006 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us/128.110.153.239:46707. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-11-20 06:54:00,007 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us/128.110.153.239:46707. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-11-20 06:54:01,008 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us/128.110.153.239:46707. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-11-20 06:54:02,008 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us/128.110.153.239:46707. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-11-20 06:54:13,015 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us/128.110.153.239:46707. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-11-20 06:54:14,016 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us/128.110.153.239:46707. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-11-20 06:54:15,017 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us/128.110.153.239:46707. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-11-20 06:54:16,019 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us/128.110.153.239:46707. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-11-20 06:54:17,020 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us/128.110.153.239:46707. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-11-20 06:54:18,021 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us/128.110.153.239:46707. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-11-20 06:54:19,022 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us/128.110.153.239:46707. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-11-20 06:54:20,023 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us/128.110.153.239:46707. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-11-20 06:54:21,024 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us/128.110.153.239:46707. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-11-20 06:54:22,025 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: cp-5.yarn-perf.yarnrm-PG0.utah.cloudlab.us/128.110.153.239:46707. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
